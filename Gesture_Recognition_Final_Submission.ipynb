{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "#from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val' #experiment with the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator(source_path, folder_list, batch_size, f, y, z):\n",
    "        print('Source path = ', source_path, '; batch size =', batch_size)\n",
    "    \n",
    "        #img_idx = np.round(np.linspace(0,29,int(f)).astype(int)\n",
    "        img_idx = np.round(np.linspace(0,29,f)).astype(int)\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data = np.zeros((batch_size,len(img_idx),y,z,3))\n",
    "                batch_labels = np.zeros((batch_size,5))\n",
    "                for folder in range(batch_size):\n",
    "                    imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0])\n",
    "                    for idx,item in enumerate(img_idx):\n",
    "                        image = io.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                        image_resized= resize(image, (y, z,3), anti_aliasing=False)\n",
    "                                             \n",
    "                                             \n",
    "                        batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                        batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                        batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                                             \n",
    "                                             \n",
    "                    batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "                    \n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data = np.zeros((remaining_seq,len(img_idx),y,z,3))\n",
    "                batch_labels = np.zeros((remaining_seq,5))\n",
    "                for folder in range(remaining_seq):\n",
    "                    imgs = os.listdir(source_path+'/'+ t[folder + (batch*remaining_seq)].split(';')[0])\n",
    "                    for idx,item in enumerate(img_idx):\n",
    "                        image = io.imread(source_path+'/'+ t[folder + (batch*remaining_seq)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                        image_resized=resize(image, (y, z,3),anti_aliasing=False)\n",
    "                        \n",
    "                                      \n",
    "                        batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                        batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                        batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                    \n",
    "                    batch_labels[folder, int(t[folder + (batch*remaining_seq)].strip().split(';')[2])] = 1\n",
    "                    \n",
    "                yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models():\n",
    "    @classmethod\n",
    "    def cnn_1(cls, input_shape):\n",
    "        \n",
    "        nb_dense = [256]\n",
    "        nb_filters = [8,16,32,64]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(nb_filters[0],(3,3,3),padding='same',use_bias=False,input_shape= input_shape)) #(16,96,96,3)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv3D(nb_filters[1],(3,3,3),padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[2], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[3], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(nb_dense[0],use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.5))\n",
    "        \n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def cnn_2(cls, input_shape):\n",
    "        \n",
    "        nb_dense = [256]\n",
    "        nb_filters = [8,16,32,64,128]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(nb_filters[0],(3,3,3),padding='same',use_bias=False,input_shape= input_shape)) #(16,96,96,3)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv3D(nb_filters[1],(3,3,3),padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[2], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[3], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[4], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(nb_dense[0],use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.5))\n",
    "        \n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def conv_l2(cls, input_shape):\n",
    "        nb_dense = [256]\n",
    "        nb_filters = [8,16,32,64,128]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(nb_filters[0],(3,3,3),padding='same',use_bias=False,input_shape= input_shape)) #(16,96,96,3)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv3D(nb_filters[1],(3,3,3),padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[2], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[3], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[4], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256,kernel_regularizer=l2(0.01)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def conv_Increasedl2(cls, input_shape):\n",
    "        nb_dense = [256]\n",
    "        nb_filters = [8,16,32,64,128]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(nb_filters[0],(3,3,3),padding='same',use_bias=False,input_shape= input_shape)) #(16,96,96,3)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv3D(nb_filters[1],(3,3,3),padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[2], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[3], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[4], (3,3,3), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256,kernel_regularizer=l2(0.035)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def conv_lstm_gru(cls, input_shape):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape= input_shape))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3,3), activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (2,2),padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.3))\n",
    "                  \n",
    "        model.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "        model.add(GRU(128, return_sequences=False))\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def conv_lstm(cls, input_shape):\n",
    "    \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(8, (7, 7), strides=(2, 2),\n",
    "            activation='relu', padding='same'), input_shape=input_shape))\n",
    "        model.add(TimeDistributed(Conv2D(8, (3,3),\n",
    "            kernel_initializer=\"he_normal\", activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(16, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    @classmethod\n",
    "    def conv_lstm_gru_updated(cls, input_shape):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape= input_shape))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3,3), activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.15))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (2,2),padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.15))\n",
    "                  \n",
    "        model.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.15))\n",
    "        \n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        \n",
    "        model.add(Dense(64, kernel_regularizer=l2(0.01), activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        \n",
    "        model.add(Dense(256,kernel_regularizer=l2(0.035)))\n",
    "        model.add(GRU(128, return_sequences=False))\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def conv_rnn(cls, input_shape):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape= input_shape))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3,3), activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (2,2),padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(Dropout(0.6))\n",
    "        \n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        \n",
    "        model.add(Dense(64, kernel_regularizer=l2(0.01), activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, kernel_regularizer=l2(0.01), activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(GRU(128, return_sequences=False))\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    @classmethod\n",
    "    def cnn_3(cls, input_shape):\n",
    "\n",
    "        nb_dense = [256]\n",
    "        nb_filters = [8,16,32,64]\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(nb_filters[0],(3,3,3),padding='same',use_bias=False,input_shape= input_shape)) #(16,96,96,3)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv3D(nb_filters[1],(3,3,3),padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[2], (2,2,2), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(nb_filters[3], (2,2,2), padding='same',use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(64,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Dense(64,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(batch_size, num_epochs, model, train_generator, val_generator, name = 'model', optimiser=None):\n",
    "    \n",
    "    curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "    num_train_sequences = len(train_doc)\n",
    "    print('# training sequences =', num_train_sequences)\n",
    "    num_val_sequences = len(val_doc)\n",
    "    print('# validation sequences =', num_val_sequences)\n",
    "    num_epochs = num_epochs # choose the number of epochs\n",
    "    print ('# epochs =', num_epochs)\n",
    "    \n",
    "    \n",
    "    if optimiser == None:\n",
    "        optimiser = Adam(lr = 0.001) \n",
    "    else:\n",
    "        optimiser = optimizers.Adam(lr= 0.0002)\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "\n",
    "    #filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "    filepath = model_name + 'model-'+name+'.h5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "\n",
    "    callbacks_list = [checkpoint, LR]\n",
    "    \n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "    history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "    return history\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "import matplotlib.pyplot as plt\n",
    "def loss(history):\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================   Checking for LR=0.1  ========================================\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 257s 2s/step - loss: 5.7403 - categorical_accuracy: 0.2877 - val_loss: 3.8691 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/3\n",
      "133/133 [==============================] - 131s 985ms/step - loss: 1.5507 - categorical_accuracy: 0.2737 - val_loss: 1.4810 - val_categorical_accuracy: 0.3200\n",
      "Epoch 3/3\n",
      "133/133 [==============================] - 142s 1s/step - loss: 1.5653 - categorical_accuracy: 0.2587 - val_loss: 1.5005 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.09000000134110452.\n",
      "\n",
      "\n",
      "========================================   Checking for LR=0.01  ========================================\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/trainEpoch 1/3\n",
      " ; batch size = 5\n",
      "133/133 [==============================] - 134s 1s/step - loss: 1.9368 - categorical_accuracy: 0.3378 - val_loss: 6.2855 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/3\n",
      "133/133 [==============================] - 105s 792ms/step - loss: 1.5937 - categorical_accuracy: 0.4070 - val_loss: 1.1052 - val_categorical_accuracy: 0.5900\n",
      "Epoch 3/3\n",
      "133/133 [==============================] - 111s 833ms/step - loss: 1.2397 - categorical_accuracy: 0.4907 - val_loss: 1.6964 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "\n",
      "\n",
      "========================================   Checking for LR=0.001  ========================================\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/3\n",
      "133/133 [==============================] - 113s 847ms/step - loss: 1.5363 - categorical_accuracy: 0.4476 - val_loss: 1.3181 - val_categorical_accuracy: 0.5400\n",
      "Epoch 2/3\n",
      "133/133 [==============================] - 116s 873ms/step - loss: 1.1463 - categorical_accuracy: 0.5789 - val_loss: 1.9369 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 3/3\n",
      "133/133 [==============================] - 100s 750ms/step - loss: 1.0045 - categorical_accuracy: 0.6411 - val_loss: 1.4890 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "\n",
    "# range of learning rates to tune\n",
    "hyper_parameters_for_lr = [0.1, 0.01, 0.001]\n",
    "\n",
    "# callback to append loss\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "# instantiate a LossHistory() object to store histories\n",
    "history = LossHistory()\n",
    "plot_data = {}\n",
    "input_shape = (30,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 10\n",
    "\n",
    "model_def = Models()\n",
    "\n",
    "num_train_sequences = len(train_doc)\n",
    "num_val_sequences = len(val_doc)\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1, cooldown=1, verbose=1)\n",
    "    \n",
    "# for each hyperparam: train the model and plot loss history\n",
    "for lr in hyper_parameters_for_lr:\n",
    "    print ('\\n\\n'+'=='*20 + '   Checking for LR={}  '.format(lr) + '=='*20 )\n",
    "    optimiser = Adam(lr)\n",
    "    \n",
    "    # model and generators\n",
    "    model = model_def.cnn_1(input_shape)\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    training_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "    validation_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "    \n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "        \n",
    "    \n",
    "    model.fit_generator(training_generator, steps_per_epoch=steps_per_epoch, epochs=3, verbose=1, \n",
    "                    callbacks=[history, LR], validation_data=validation_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "    \n",
    "    # plot loss history\n",
    "    plot_data[lr] = history.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss history for each value of hyperparameter with ReduceLROnPlateau enabled for patience=1 and factor=0.9\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "f, axes = plt.subplots(1, 3, sharey=True)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "plt.setp(axes, xticks=np.arange(0, len(plot_data[0.01]), 1)+1)\n",
    "\n",
    "for i, lr in enumerate(plot_data.keys()):\n",
    "    axes[i].plot(np.arange(len(plot_data[lr]))+1, plot_data[lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR=0.001 seems to exhibit lower loss and high accuracy on train and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_49 (Conv3D)           (None, 30, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 30, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 30, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_49 (MaxPooling (None, 30, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_50 (Conv3D)           (None, 30, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 30, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 30, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_50 (MaxPooling (None, 15, 24, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_51 (Conv3D)           (None, 15, 24, 24, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 15, 24, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 15, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_51 (MaxPooling (None, 7, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_52 (Conv3D)           (None, 7, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 7, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 7, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_52 (MaxPooling (None, 3, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               1769472   \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,845,485\n",
      "Trainable params: 1,844,733\n",
      "Non-trainable params: 752\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5Epoch 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 118s 886ms/step - loss: 1.4841 - categorical_accuracy: 0.4702 - val_loss: 1.6549 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.65485, saving model to model_init_2020-11-0713_52_56.598678/model-cnn_1_b5_e10.h5\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 98s 740ms/step - loss: 1.0514 - categorical_accuracy: 0.6100 - val_loss: 1.4388 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.65485 to 1.43876, saving model to model_init_2020-11-0713_52_56.598678/model-cnn_1_b5_e10.h5\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 106s 795ms/step - loss: 1.0452 - categorical_accuracy: 0.6165 - val_loss: 1.3998 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.43876 to 1.39979, saving model to model_init_2020-11-0713_52_56.598678/model-cnn_1_b5_e10.h5\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 106s 793ms/step - loss: 0.9049 - categorical_accuracy: 0.6622 - val_loss: 1.4192 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.39979\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 108s 815ms/step - loss: 0.8334 - categorical_accuracy: 0.6892 - val_loss: 1.9042 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.39979\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 101s 763ms/step - loss: 0.7653 - categorical_accuracy: 0.7263 - val_loss: 0.7319 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.39979 to 0.73194, saving model to model_init_2020-11-0713_52_56.598678/model-cnn_1_b5_e10.h5\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 114s 859ms/step - loss: 0.6707 - categorical_accuracy: 0.7449 - val_loss: 0.7385 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.73194\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 107s 803ms/step - loss: 0.6458 - categorical_accuracy: 0.7644 - val_loss: 1.1864 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.73194\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 102s 766ms/step - loss: 0.5275 - categorical_accuracy: 0.7945 - val_loss: 0.9529 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.73194\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 101s 760ms/step - loss: 0.5173 - categorical_accuracy: 0.8105 - val_loss: 0.7513 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.73194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_def = Models()\n",
    "input_shape = (30,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 10\n",
    "\n",
    "model = model_def.cnn_1(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_1_b5_e10_f30_i96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_53 (Conv3D)           (None, 30, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 30, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 30, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_53 (MaxPooling (None, 30, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_54 (Conv3D)           (None, 30, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 30, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 30, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_54 (MaxPooling (None, 15, 24, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_55 (Conv3D)           (None, 15, 24, 24, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 15, 24, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 15, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_55 (MaxPooling (None, 7, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_56 (Conv3D)           (None, 7, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 7, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 7, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_56 (MaxPooling (None, 3, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               1769472   \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,845,485\n",
      "Trainable params: 1,844,733\n",
      "Non-trainable params: 752\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 114s 860ms/step - loss: 1.6734 - categorical_accuracy: 0.3935 - val_loss: 2.2898 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.28977, saving model to model_init_2020-11-0714_10_49.285766/model-cnn_1_b5_e15.h5\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 106s 796ms/step - loss: 1.2539 - categorical_accuracy: 0.5163 - val_loss: 2.6717 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.28977\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 104s 786ms/step - loss: 1.0500 - categorical_accuracy: 0.6005 - val_loss: 2.1823 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.28977 to 2.18226, saving model to model_init_2020-11-0714_10_49.285766/model-cnn_1_b5_e15.h5\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 109s 817ms/step - loss: 0.8892 - categorical_accuracy: 0.6667 - val_loss: 0.8167 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.18226 to 0.81674, saving model to model_init_2020-11-0714_10_49.285766/model-cnn_1_b5_e15.h5\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 105s 786ms/step - loss: 0.7510 - categorical_accuracy: 0.7103 - val_loss: 0.6853 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.81674 to 0.68534, saving model to model_init_2020-11-0714_10_49.285766/model-cnn_1_b5_e15.h5\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 107s 806ms/step - loss: 0.6337 - categorical_accuracy: 0.7614 - val_loss: 0.7683 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.68534\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 113s 848ms/step - loss: 0.6235 - categorical_accuracy: 0.7609 - val_loss: 3.0664 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.68534\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 101s 762ms/step - loss: 0.5832 - categorical_accuracy: 0.7759 - val_loss: 1.1132 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.68534\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 102s 769ms/step - loss: 0.4205 - categorical_accuracy: 0.8451 - val_loss: 1.2421 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68534\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 103s 771ms/step - loss: 0.5358 - categorical_accuracy: 0.7990 - val_loss: 0.8170 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.68534\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 110s 826ms/step - loss: 0.5242 - categorical_accuracy: 0.8080 - val_loss: 1.3166 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.68534\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 103s 771ms/step - loss: 0.4545 - categorical_accuracy: 0.8411 - val_loss: 0.7533 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.68534\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 104s 782ms/step - loss: 0.3336 - categorical_accuracy: 0.8797 - val_loss: 0.5926 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68534 to 0.59257, saving model to model_init_2020-11-0714_10_49.285766/model-cnn_1_b5_e15.h5\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 101s 760ms/step - loss: 0.3677 - categorical_accuracy: 0.8802 - val_loss: 0.6388 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59257\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 106s 795ms/step - loss: 0.3611 - categorical_accuracy: 0.8817 - val_loss: 0.4623 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.59257 to 0.46227, saving model to model_init_2020-11-0714_10_49.285766/model-cnn_1_b5_e15.h5\n"
     ]
    }
   ],
   "source": [
    "# write up\n",
    "\n",
    "model_def = Models()\n",
    "input_shape = (30,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 15\n",
    "\n",
    "model = model_def.cnn_1(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_1_b5_e15_f30_i96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_61 (Conv3D)           (None, 30, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 30, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 30, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_61 (MaxPooling (None, 30, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_62 (Conv3D)           (None, 30, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 30, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 30, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_62 (MaxPooling (None, 15, 24, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_63 (Conv3D)           (None, 15, 24, 24, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 15, 24, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 15, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_63 (MaxPooling (None, 7, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_64 (Conv3D)           (None, 7, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 7, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 7, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_64 (MaxPooling (None, 3, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               1769472   \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,845,485\n",
      "Trainable params: 1,844,733\n",
      "Non-trainable params: 752\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/trainEpoch 1/30\n",
      " ; batch size = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 125s 941ms/step - loss: 1.6383 - categorical_accuracy: 0.4145 - val_loss: 2.3521 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.35206, saving model to model_init_2020-11-0715_08_43.781435/model-cnn_1_b5_e30.h5\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 97s 732ms/step - loss: 1.1978 - categorical_accuracy: 0.5388 - val_loss: 3.3086 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.35206\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 103s 774ms/step - loss: 0.9780 - categorical_accuracy: 0.6351 - val_loss: 0.8887 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.35206 to 0.88869, saving model to model_init_2020-11-0715_08_43.781435/model-cnn_1_b5_e30.h5\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 104s 784ms/step - loss: 0.8636 - categorical_accuracy: 0.6742 - val_loss: 1.7827 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.88869\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 109s 822ms/step - loss: 0.7909 - categorical_accuracy: 0.6957 - val_loss: 0.9160 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.88869\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 103s 777ms/step - loss: 0.6747 - categorical_accuracy: 0.7524 - val_loss: 1.4362 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.88869\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 101s 758ms/step - loss: 0.5097 - categorical_accuracy: 0.8195 - val_loss: 0.5708 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.88869 to 0.57083, saving model to model_init_2020-11-0715_08_43.781435/model-cnn_1_b5_e30.h5\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 104s 784ms/step - loss: 0.5700 - categorical_accuracy: 0.7840 - val_loss: 1.3288 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57083\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 110s 826ms/step - loss: 0.4905 - categorical_accuracy: 0.8271 - val_loss: 1.3391 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.57083\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 104s 783ms/step - loss: 0.4963 - categorical_accuracy: 0.8276 - val_loss: 1.1701 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57083\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 104s 778ms/step - loss: 0.4528 - categorical_accuracy: 0.8421 - val_loss: 0.7175 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.57083\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 106s 795ms/step - loss: 0.4736 - categorical_accuracy: 0.8331 - val_loss: 0.9173 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.57083\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 100s 755ms/step - loss: 0.3490 - categorical_accuracy: 0.8737 - val_loss: 0.5914 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57083\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 102s 770ms/step - loss: 0.2829 - categorical_accuracy: 0.8967 - val_loss: 0.7540 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.57083\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 104s 782ms/step - loss: 0.3345 - categorical_accuracy: 0.8822 - val_loss: 0.5834 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.57083\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 101s 762ms/step - loss: 0.2519 - categorical_accuracy: 0.9188 - val_loss: 0.5821 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.57083\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 108s 813ms/step - loss: 0.2454 - categorical_accuracy: 0.9158 - val_loss: 0.7653 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57083\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 113s 849ms/step - loss: 0.2176 - categorical_accuracy: 0.9203 - val_loss: 0.8110 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.57083\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 103s 775ms/step - loss: 0.2190 - categorical_accuracy: 0.9303 - val_loss: 0.6646 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.57083\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 103s 776ms/step - loss: 0.2132 - categorical_accuracy: 0.9298 - val_loss: 0.6699 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.57083\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 101s 756ms/step - loss: 0.1465 - categorical_accuracy: 0.9654 - val_loss: 0.6936 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.57083\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 103s 776ms/step - loss: 0.1210 - categorical_accuracy: 0.9669 - val_loss: 0.5104 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.57083 to 0.51040, saving model to model_init_2020-11-0715_08_43.781435/model-cnn_1_b5_e30.h5\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 103s 776ms/step - loss: 0.1537 - categorical_accuracy: 0.9464 - val_loss: 0.8039 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51040\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 100s 754ms/step - loss: 0.1511 - categorical_accuracy: 0.9534 - val_loss: 1.0767 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51040\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 106s 795ms/step - loss: 0.1702 - categorical_accuracy: 0.9449 - val_loss: 0.6552 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.51040\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 99s 747ms/step - loss: 0.1707 - categorical_accuracy: 0.9398 - val_loss: 0.9683 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.51040\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 104s 778ms/step - loss: 0.1233 - categorical_accuracy: 0.9564 - val_loss: 1.0112 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.51040\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 110s 828ms/step - loss: 0.1755 - categorical_accuracy: 0.9444 - val_loss: 0.7015 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.51040\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 112s 844ms/step - loss: 0.1340 - categorical_accuracy: 0.9609 - val_loss: 0.7112 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.51040\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 101s 757ms/step - loss: 0.1883 - categorical_accuracy: 0.9268 - val_loss: 0.8987 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.51040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_def = Models()\n",
    "input_shape = (30,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 30\n",
    "\n",
    "model = model_def.cnn_1(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_1_b5_e30_f30_i96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_57 (Conv3D)           (None, 16, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 16, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_57 (MaxPooling (None, 16, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_58 (Conv3D)           (None, 16, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 16, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_58 (MaxPooling (None, 8, 24, 24, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_59 (Conv3D)           (None, 8, 24, 24, 32)     13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 8, 24, 24, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 8, 24, 24, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_59 (MaxPooling (None, 4, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_60 (Conv3D)           (None, 4, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 4, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 4, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_60 (MaxPooling (None, 2, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,255,661\n",
      "Trainable params: 1,254,909\n",
      "Non-trainable params: 752\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 56s 842ms/step - loss: 1.4845 - categorical_accuracy: 0.4622 - val_loss: 3.9344 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.93443, saving model to model_init_2020-11-0714_38_33.173728/model-cnn_1_b10_e30.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 55s 817ms/step - loss: 1.0438 - categorical_accuracy: 0.6035 - val_loss: 2.2907 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.93443 to 2.29071, saving model to model_init_2020-11-0714_38_33.173728/model-cnn_1_b10_e30.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 56s 840ms/step - loss: 0.7560 - categorical_accuracy: 0.7159 - val_loss: 1.1699 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.29071 to 1.16990, saving model to model_init_2020-11-0714_38_33.173728/model-cnn_1_b10_e30.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 55s 827ms/step - loss: 0.5649 - categorical_accuracy: 0.7865 - val_loss: 1.7413 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.16990\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 54s 800ms/step - loss: 0.3885 - categorical_accuracy: 0.8488 - val_loss: 2.1811 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.16990\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 53s 797ms/step - loss: 0.3956 - categorical_accuracy: 0.8418 - val_loss: 1.2494 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.16990\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 58s 869ms/step - loss: 0.3829 - categorical_accuracy: 0.8628 - val_loss: 2.3609 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.16990\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 53s 797ms/step - loss: 0.2911 - categorical_accuracy: 0.9051 - val_loss: 1.0079 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.16990 to 1.00795, saving model to model_init_2020-11-0714_38_33.173728/model-cnn_1_b10_e30.h5\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 53s 794ms/step - loss: 0.2751 - categorical_accuracy: 0.9080 - val_loss: 1.2437 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00795\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 53s 789ms/step - loss: 0.2639 - categorical_accuracy: 0.9025 - val_loss: 0.6476 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00795 to 0.64765, saving model to model_init_2020-11-0714_38_33.173728/model-cnn_1_b10_e30.h5\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 61s 916ms/step - loss: 0.2008 - categorical_accuracy: 0.9384 - val_loss: 0.6643 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.64765\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 57s 846ms/step - loss: 0.1642 - categorical_accuracy: 0.9463 - val_loss: 0.7557 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.64765\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 53s 786ms/step - loss: 0.1688 - categorical_accuracy: 0.9552 - val_loss: 1.0324 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.64765\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 54s 807ms/step - loss: 0.1390 - categorical_accuracy: 0.9612 - val_loss: 0.8965 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.64765\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 58s 867ms/step - loss: 0.0764 - categorical_accuracy: 0.9851 - val_loss: 0.6389 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.64765 to 0.63890, saving model to model_init_2020-11-0714_38_33.173728/model-cnn_1_b10_e30.h5\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 53s 791ms/step - loss: 0.1432 - categorical_accuracy: 0.9588 - val_loss: 1.1180 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.63890\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 61s 916ms/step - loss: 0.1918 - categorical_accuracy: 0.9328 - val_loss: 2.0077 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.63890\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 54s 800ms/step - loss: 0.1091 - categorical_accuracy: 0.9701 - val_loss: 1.5059 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.63890\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 54s 808ms/step - loss: 0.1114 - categorical_accuracy: 0.9712 - val_loss: 0.8840 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.63890\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 54s 802ms/step - loss: 0.1364 - categorical_accuracy: 0.9518 - val_loss: 0.8923 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.63890\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 62s 923ms/step - loss: 0.1393 - categorical_accuracy: 0.9503 - val_loss: 1.7031 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.63890\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 55s 814ms/step - loss: 0.1013 - categorical_accuracy: 0.9712 - val_loss: 1.0083 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.63890\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 61s 905ms/step - loss: 0.0931 - categorical_accuracy: 0.9761 - val_loss: 0.9096 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.63890\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 56s 829ms/step - loss: 0.0582 - categorical_accuracy: 0.9836 - val_loss: 0.8092 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.63890\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 53s 792ms/step - loss: 0.0615 - categorical_accuracy: 0.9836 - val_loss: 1.0233 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.63890\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 61s 916ms/step - loss: 0.0407 - categorical_accuracy: 0.9925 - val_loss: 1.1378 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.63890\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 56s 834ms/step - loss: 0.0994 - categorical_accuracy: 0.9827 - val_loss: 0.7526 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.63890\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 55s 823ms/step - loss: 0.0668 - categorical_accuracy: 0.9896 - val_loss: 0.6973 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.63890\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 59s 886ms/step - loss: 0.0333 - categorical_accuracy: 0.9940 - val_loss: 0.8429 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.63890\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 59s 887ms/step - loss: 0.0276 - categorical_accuracy: 0.9940 - val_loss: 0.8558 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.63890\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n"
     ]
    }
   ],
   "source": [
    "# For write up 2\n",
    "\n",
    "model_def = Models()\n",
    "input_shape = (16,96,96, 3)\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "model = model_def.cnn_1(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_1_b10_e30_f16_i96')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 16, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 16, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 24, 24, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 8, 24, 24, 32)     13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 24, 24, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 24, 24, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 4, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 2, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 592,621\n",
      "Trainable params: 591,613\n",
      "Non-trainable params: 1,008\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Epoch 1/15\n",
      "Project_data/train ; batch size = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 172s 1s/step - loss: 1.7174 - categorical_accuracy: 0.3724 - val_loss: 3.1363 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.13631, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 72s 538ms/step - loss: 1.3991 - categorical_accuracy: 0.4581 - val_loss: 3.0326 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.13631 to 3.03259, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 71s 534ms/step - loss: 1.1855 - categorical_accuracy: 0.5268 - val_loss: 2.0540 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.03259 to 2.05397, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 72s 544ms/step - loss: 1.1420 - categorical_accuracy: 0.5679 - val_loss: 1.6347 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.05397 to 1.63469, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 73s 547ms/step - loss: 0.9427 - categorical_accuracy: 0.6426 - val_loss: 1.0842 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.63469 to 1.08417, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 90s 676ms/step - loss: 0.8619 - categorical_accuracy: 0.6962 - val_loss: 1.7049 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.08417\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 53s 399ms/step - loss: 0.7661 - categorical_accuracy: 0.7093 - val_loss: 1.9064 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.08417\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 54s 408ms/step - loss: 0.7072 - categorical_accuracy: 0.7238 - val_loss: 1.2192 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.08417\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 55s 417ms/step - loss: 0.6902 - categorical_accuracy: 0.7479 - val_loss: 0.8607 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.08417 to 0.86069, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 56s 419ms/step - loss: 0.6040 - categorical_accuracy: 0.7584 - val_loss: 0.8345 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.86069 to 0.83447, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 57s 426ms/step - loss: 0.6659 - categorical_accuracy: 0.7424 - val_loss: 1.7694 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.83447\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 54s 403ms/step - loss: 0.6148 - categorical_accuracy: 0.7604 - val_loss: 0.6676 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.83447 to 0.66758, saving model to model_init_2020-11-0716_25_45.533320/model-cnn_2_b5_e15.h5\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 58s 438ms/step - loss: 0.4267 - categorical_accuracy: 0.8421 - val_loss: 0.6783 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.66758\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 0.4271 - categorical_accuracy: 0.8541 - val_loss: 0.7039 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.66758\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 54s 409ms/step - loss: 0.3472 - categorical_accuracy: 0.8827 - val_loss: 1.5385 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.66758\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n"
     ]
    }
   ],
   "source": [
    "# Write up\n",
    "\n",
    "model = Models()\n",
    "input_shape = (16,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 15\n",
    "\n",
    "model = model.cnn_2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_2_b5_e15_f16_i96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_11 (Conv3D)           (None, 16, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 16, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 16, 60, 60, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 8, 30, 30, 32)     13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 4, 15, 15, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 4, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 2, 7, 7, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 2, 7, 7, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 2, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 592,621\n",
      "Trainable params: 591,613\n",
      "Non-trainable params: 1,008\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 66s 988ms/step - loss: 1.4439 - categorical_accuracy: 0.4602 - val_loss: 2.1220 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.12200, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 63s 940ms/step - loss: 1.0441 - categorical_accuracy: 0.6070 - val_loss: 2.0331 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.12200 to 2.03307, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 60s 891ms/step - loss: 0.9232 - categorical_accuracy: 0.6607 - val_loss: 1.5086 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.03307 to 1.50857, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 60s 891ms/step - loss: 0.7802 - categorical_accuracy: 0.7144 - val_loss: 3.0641 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.50857\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 61s 914ms/step - loss: 0.6372 - categorical_accuracy: 0.7513 - val_loss: 1.1050 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.50857 to 1.10495, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 60s 898ms/step - loss: 0.5421 - categorical_accuracy: 0.8010 - val_loss: 1.5233 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.10495\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 60s 900ms/step - loss: 0.4921 - categorical_accuracy: 0.8230 - val_loss: 0.9146 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.10495 to 0.91460, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 61s 904ms/step - loss: 0.4635 - categorical_accuracy: 0.8164 - val_loss: 1.0345 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.91460\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 60s 897ms/step - loss: 0.4023 - categorical_accuracy: 0.8368 - val_loss: 1.0961 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.91460\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 60s 893ms/step - loss: 0.3834 - categorical_accuracy: 0.8582 - val_loss: 2.1370 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.91460\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 59s 884ms/step - loss: 0.2751 - categorical_accuracy: 0.8951 - val_loss: 0.6590 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.91460 to 0.65904, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 62s 925ms/step - loss: 0.2526 - categorical_accuracy: 0.9040 - val_loss: 1.2370 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.65904\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 60s 894ms/step - loss: 0.2264 - categorical_accuracy: 0.9179 - val_loss: 1.5235 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.65904\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 62s 926ms/step - loss: 0.2619 - categorical_accuracy: 0.9119 - val_loss: 0.8513 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.65904\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 62s 925ms/step - loss: 0.2095 - categorical_accuracy: 0.9403 - val_loss: 1.8698 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.65904\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 59s 886ms/step - loss: 0.1358 - categorical_accuracy: 0.9552 - val_loss: 0.6940 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.65904\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 62s 929ms/step - loss: 0.1591 - categorical_accuracy: 0.9463 - val_loss: 2.9785 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.65904\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 60s 892ms/step - loss: 0.1373 - categorical_accuracy: 0.9582 - val_loss: 1.7224 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.65904\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 61s 916ms/step - loss: 0.1390 - categorical_accuracy: 0.9563 - val_loss: 1.1491 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.65904\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 62s 927ms/step - loss: 0.1433 - categorical_accuracy: 0.9463 - val_loss: 1.6737 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.65904\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 59s 881ms/step - loss: 0.0798 - categorical_accuracy: 0.9757 - val_loss: 0.7012 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.65904\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 60s 891ms/step - loss: 0.0902 - categorical_accuracy: 0.9687 - val_loss: 1.2615 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.65904\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 62s 927ms/step - loss: 0.1550 - categorical_accuracy: 0.9633 - val_loss: 2.8957 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.65904\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 68s 1s/step - loss: 0.2398 - categorical_accuracy: 0.9309 - val_loss: 0.6349 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.65904 to 0.63486, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 60s 892ms/step - loss: 0.1516 - categorical_accuracy: 0.9518 - val_loss: 0.5782 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.63486 to 0.57817, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 63s 941ms/step - loss: 0.1098 - categorical_accuracy: 0.9657 - val_loss: 0.9746 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.57817\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 66s 987ms/step - loss: 0.0847 - categorical_accuracy: 0.9742 - val_loss: 0.7015 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.57817\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 62s 926ms/step - loss: 0.0713 - categorical_accuracy: 0.9772 - val_loss: 0.7404 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.57817\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 59s 884ms/step - loss: 0.1020 - categorical_accuracy: 0.9716 - val_loss: 1.1630 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.57817\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 60s 889ms/step - loss: 0.0761 - categorical_accuracy: 0.9791 - val_loss: 0.5597 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.57817 to 0.55970, saving model to model_init_2020-11-0717_04_41.711857/model-cnn_2_b5_e15.h5\n"
     ]
    }
   ],
   "source": [
    "model = Models()\n",
    "input_shape = (16,120,120, 3)\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "model = model.cnn_2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_2_b5_e15_f16_i120')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_16 (Conv3D)           (None, 30, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 30, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 30, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 30, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 30, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 15, 24, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 15, 24, 24, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 15, 24, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 15, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 7, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 7, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 7, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 7, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 3, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 3, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 3, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 3, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Epoch 1/20Project_data/train ; batch size = 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 190s 1s/step - loss: 4.8142 - categorical_accuracy: 0.3353 - val_loss: 3.4110 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.41103, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - 108s 814ms/step - loss: 3.1204 - categorical_accuracy: 0.4015 - val_loss: 3.0501 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.41103 to 3.05011, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - 97s 728ms/step - loss: 2.4732 - categorical_accuracy: 0.4561 - val_loss: 1.8903 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.05011 to 1.89031, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - 100s 750ms/step - loss: 1.8601 - categorical_accuracy: 0.5434 - val_loss: 1.7717 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.89031 to 1.77167, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - 103s 776ms/step - loss: 1.5698 - categorical_accuracy: 0.5950 - val_loss: 1.9147 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.77167\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - 105s 791ms/step - loss: 1.2601 - categorical_accuracy: 0.6652 - val_loss: 1.4601 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.77167 to 1.46010, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - 96s 725ms/step - loss: 1.0719 - categorical_accuracy: 0.7338 - val_loss: 1.1430 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.46010 to 1.14299, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - 95s 716ms/step - loss: 0.9068 - categorical_accuracy: 0.7729 - val_loss: 0.9331 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.14299 to 0.93312, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - 97s 726ms/step - loss: 0.8388 - categorical_accuracy: 0.7734 - val_loss: 1.9504 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.93312\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - 107s 805ms/step - loss: 0.7537 - categorical_accuracy: 0.8005 - val_loss: 0.8952 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.93312 to 0.89520, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - 103s 776ms/step - loss: 0.6237 - categorical_accuracy: 0.8351 - val_loss: 1.0369 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.89520\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - 98s 739ms/step - loss: 0.5889 - categorical_accuracy: 0.8496 - val_loss: 0.5729 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.89520 to 0.57291, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - 97s 733ms/step - loss: 0.4852 - categorical_accuracy: 0.8887 - val_loss: 0.8616 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57291\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - 98s 735ms/step - loss: 0.4566 - categorical_accuracy: 0.8842 - val_loss: 0.5509 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.57291 to 0.55089, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - 106s 797ms/step - loss: 0.3960 - categorical_accuracy: 0.9013 - val_loss: 0.6138 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.55089\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - 95s 716ms/step - loss: 0.3779 - categorical_accuracy: 0.9188 - val_loss: 0.5418 - val_categorical_accuracy: 0.8700\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.55089 to 0.54180, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - 97s 731ms/step - loss: 0.2976 - categorical_accuracy: 0.9489 - val_loss: 0.8687 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.54180\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - 97s 730ms/step - loss: 0.3458 - categorical_accuracy: 0.9278 - val_loss: 0.7822 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.54180\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - 98s 734ms/step - loss: 0.2856 - categorical_accuracy: 0.9489 - val_loss: 1.4234 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.54180\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - 104s 781ms/step - loss: 0.2561 - categorical_accuracy: 0.9654 - val_loss: 0.4190 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.54180 to 0.41896, saving model to model_init_2020-11-0717_37_18.535712/model-conv_l2_b5_e20_i96.h5\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - write up\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (30,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 20\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b5_e20_f_30_i96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_21 (Conv3D)           (None, 20, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 20, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 20, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 20, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 20, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 20, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 20, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 10, 24, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 10, 24, 24, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 10, 24, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 5, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 5, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 5, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 5, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_24 (MaxPooling (None, 2, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 2, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 2, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_25 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 10Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 73s 1s/step - loss: 5.4400 - categorical_accuracy: 0.3000 - val_loss: 5.0175 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.01752, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 70s 1s/step - loss: 3.7570 - categorical_accuracy: 0.4233 - val_loss: 3.2210 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.01752 to 3.22097, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 67s 1s/step - loss: 3.1751 - categorical_accuracy: 0.4308 - val_loss: 2.7705 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.22097 to 2.77049, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 71s 1s/step - loss: 2.6887 - categorical_accuracy: 0.4717 - val_loss: 2.3463 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.77049 to 2.34632, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 66s 991ms/step - loss: 2.2810 - categorical_accuracy: 0.4925 - val_loss: 2.1151 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.34632 to 2.11506, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 66s 991ms/step - loss: 1.9117 - categorical_accuracy: 0.5707 - val_loss: 2.3371 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.11506\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 66s 981ms/step - loss: 1.7409 - categorical_accuracy: 0.5732 - val_loss: 1.4580 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.11506 to 1.45798, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 74s 1s/step - loss: 1.5862 - categorical_accuracy: 0.6223 - val_loss: 1.6856 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.45798\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 67s 994ms/step - loss: 1.2464 - categorical_accuracy: 0.7189 - val_loss: 1.2622 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.45798 to 1.26218, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 66s 984ms/step - loss: 1.2000 - categorical_accuracy: 0.6946 - val_loss: 4.6571 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.26218\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 71s 1s/step - loss: 1.0236 - categorical_accuracy: 0.7453 - val_loss: 2.2947 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.26218\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 66s 989ms/step - loss: 0.9424 - categorical_accuracy: 0.7756 - val_loss: 1.0274 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.26218 to 1.02737, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 67s 998ms/step - loss: 0.7793 - categorical_accuracy: 0.8059 - val_loss: 2.4254 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.02737\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 68s 1s/step - loss: 0.7870 - categorical_accuracy: 0.8095 - val_loss: 1.6626 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.02737\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.6896 - categorical_accuracy: 0.8283 - val_loss: 1.6220 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.02737\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 71s 1s/step - loss: 0.5556 - categorical_accuracy: 0.8791 - val_loss: 1.8619 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.02737\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.5700 - categorical_accuracy: 0.8673 - val_loss: 0.7964 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.02737 to 0.79635, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 70s 1s/step - loss: 0.5484 - categorical_accuracy: 0.8592 - val_loss: 0.8661 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.79635\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 67s 996ms/step - loss: 0.4623 - categorical_accuracy: 0.8966 - val_loss: 1.3612 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.79635\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 67s 994ms/step - loss: 0.3862 - categorical_accuracy: 0.9269 - val_loss: 0.7249 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.79635 to 0.72490, saving model to model_init_2020-11-0816_37_29.646139/model-conv_l2_b10_e20_i96_f20.h5\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - L2b10 - Best model\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (20,96,96, 3)\n",
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b10_e20_f20_i96')\n",
    "#loss_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_26 (Conv3D)           (None, 18, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 18, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 18, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 18, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 18, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 18, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 18, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 9, 24, 24, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 9, 24, 24, 32)     13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 9, 24, 24, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 9, 24, 24, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 4, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 4, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 4, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 4, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 2, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 2, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 2, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 2, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_30 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 114s 861ms/step - loss: 4.9992 - categorical_accuracy: 0.3624 - val_loss: 3.7021 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.70206, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 65s 490ms/step - loss: 3.3776 - categorical_accuracy: 0.4190 - val_loss: 2.8203 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.70206 to 2.82029, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 64s 483ms/step - loss: 2.6268 - categorical_accuracy: 0.5008 - val_loss: 2.7529 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.82029 to 2.75290, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 62s 468ms/step - loss: 2.1475 - categorical_accuracy: 0.5413 - val_loss: 1.7635 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.75290 to 1.76347, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 61s 457ms/step - loss: 1.8324 - categorical_accuracy: 0.5714 - val_loss: 1.4103 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.76347 to 1.41035, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 63s 472ms/step - loss: 1.5292 - categorical_accuracy: 0.6170 - val_loss: 3.6443 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.41035\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 62s 469ms/step - loss: 1.3143 - categorical_accuracy: 0.6261 - val_loss: 1.8961 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.41035\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 65s 488ms/step - loss: 1.1649 - categorical_accuracy: 0.6732 - val_loss: 1.2229 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.41035 to 1.22286, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 61s 458ms/step - loss: 0.9900 - categorical_accuracy: 0.7178 - val_loss: 1.2112 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.22286 to 1.21116, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 64s 478ms/step - loss: 0.9643 - categorical_accuracy: 0.7143 - val_loss: 1.7031 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.21116\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 63s 476ms/step - loss: 0.8437 - categorical_accuracy: 0.7489 - val_loss: 0.8602 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.21116 to 0.86017, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 61s 462ms/step - loss: 0.7452 - categorical_accuracy: 0.7835 - val_loss: 1.4504 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.86017\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 66s 493ms/step - loss: 0.7201 - categorical_accuracy: 0.8005 - val_loss: 1.0420 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.86017\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 63s 473ms/step - loss: 0.6639 - categorical_accuracy: 0.8050 - val_loss: 0.8718 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.86017\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 64s 481ms/step - loss: 0.6079 - categorical_accuracy: 0.8391 - val_loss: 0.6743 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.86017 to 0.67431, saving model to model_init_2020-11-0817_01_38.743453/model-conv_l2_b10_e20_i96_f18.h5\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - L2b5f18 - Best model 2\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (18,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 15\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b10_e20_f18_i96')\n",
    "#loss_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_21 (Conv3D)           (None, 30, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 30, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 30, 60, 60, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 15, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 15, 30, 30, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 15, 30, 30, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 7, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 7, 15, 15, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 7, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_24 (MaxPooling (None, 3, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 3, 7, 7, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 3, 7, 7, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_25 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 122s 921ms/step - loss: 4.7727 - categorical_accuracy: 0.3649 - val_loss: 3.5089 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.50888, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - 110s 829ms/step - loss: 3.0726 - categorical_accuracy: 0.4426 - val_loss: 3.6115 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.50888\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - 110s 831ms/step - loss: 2.3724 - categorical_accuracy: 0.4842 - val_loss: 2.1332 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.50888 to 2.13319, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - 115s 864ms/step - loss: 1.8649 - categorical_accuracy: 0.5719 - val_loss: 1.5083 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.13319 to 1.50832, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - 110s 825ms/step - loss: 1.4806 - categorical_accuracy: 0.6386 - val_loss: 1.2634 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.50832 to 1.26339, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - 109s 817ms/step - loss: 1.2409 - categorical_accuracy: 0.7148 - val_loss: 2.9800 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.26339\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - 109s 817ms/step - loss: 1.0392 - categorical_accuracy: 0.7388 - val_loss: 1.0862 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.26339 to 1.08618, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - 114s 856ms/step - loss: 0.9013 - categorical_accuracy: 0.7825 - val_loss: 0.8698 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.08618 to 0.86979, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - 109s 819ms/step - loss: 0.7705 - categorical_accuracy: 0.8090 - val_loss: 0.7181 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.86979 to 0.71812, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - 113s 848ms/step - loss: 0.5906 - categorical_accuracy: 0.8667 - val_loss: 0.6655 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.71812 to 0.66551, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - 107s 804ms/step - loss: 0.5359 - categorical_accuracy: 0.9007 - val_loss: 1.3113 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.66551\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - 125s 939ms/step - loss: 0.5921 - categorical_accuracy: 0.8662 - val_loss: 0.7719 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.66551\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - 115s 867ms/step - loss: 0.4337 - categorical_accuracy: 0.9278 - val_loss: 0.7086 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.66551\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - 113s 847ms/step - loss: 0.3992 - categorical_accuracy: 0.9218 - val_loss: 0.5803 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.66551 to 0.58029, saving model to model_init_2020-11-0718_13_09.993209/model-conv_l2_b5_e20_i120.h5\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - 111s 835ms/step - loss: 0.3270 - categorical_accuracy: 0.9534 - val_loss: 0.7260 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.58029\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - 116s 872ms/step - loss: 0.2974 - categorical_accuracy: 0.9494 - val_loss: 0.8230 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.58029\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - 121s 909ms/step - loss: 0.2992 - categorical_accuracy: 0.9534 - val_loss: 0.7687 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.58029\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - 114s 857ms/step - loss: 0.3157 - categorical_accuracy: 0.9464 - val_loss: 1.0856 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.58029\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - 114s 861ms/step - loss: 0.2506 - categorical_accuracy: 0.9669 - val_loss: 0.7932 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.58029\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - 111s 834ms/step - loss: 0.2011 - categorical_accuracy: 0.9810 - val_loss: 0.6489 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.58029\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n"
     ]
    }
   ],
   "source": [
    "# models 3\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (30,120,120, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 20\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b5_e20_f_30_i120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_31 (Conv3D)           (None, 30, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 30, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 30, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_31 (MaxPooling (None, 30, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 30, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 30, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_32 (MaxPooling (None, 15, 24, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_33 (Conv3D)           (None, 15, 24, 24, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 15, 24, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 15, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_33 (MaxPooling (None, 7, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_34 (Conv3D)           (None, 7, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 7, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 7, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_34 (MaxPooling (None, 3, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_35 (Conv3D)           (None, 3, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 3, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 3, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_35 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 101s 2s/step - loss: 5.3753 - categorical_accuracy: 0.3318 - val_loss: 4.4588 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.45878, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 95s 1s/step - loss: 3.6847 - categorical_accuracy: 0.4686 - val_loss: 3.0661 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.45878 to 3.06606, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 96s 1s/step - loss: 2.9874 - categorical_accuracy: 0.5149 - val_loss: 2.5194 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.06606 to 2.51942, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 97s 1s/step - loss: 2.4409 - categorical_accuracy: 0.6328 - val_loss: 2.6780 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.51942\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 103s 2s/step - loss: 1.9756 - categorical_accuracy: 0.6502 - val_loss: 2.2897 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.51942 to 2.28968, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 103s 2s/step - loss: 1.7323 - categorical_accuracy: 0.7014 - val_loss: 1.8725 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.28968 to 1.87254, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 100s 1s/step - loss: 1.4353 - categorical_accuracy: 0.7428 - val_loss: 2.7650 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.87254\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 97s 1s/step - loss: 1.3000 - categorical_accuracy: 0.7522 - val_loss: 3.1397 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.87254\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 105s 2s/step - loss: 1.1431 - categorical_accuracy: 0.7776 - val_loss: 1.2463 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.87254 to 1.24633, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 101s 2s/step - loss: 0.8999 - categorical_accuracy: 0.8403 - val_loss: 1.2802 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24633\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.8011 - categorical_accuracy: 0.8627 - val_loss: 1.2526 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24633\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.7182 - categorical_accuracy: 0.8582 - val_loss: 0.9704 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.24633 to 0.97036, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.6041 - categorical_accuracy: 0.8925 - val_loss: 1.3608 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.97036\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.5672 - categorical_accuracy: 0.8925 - val_loss: 3.2598 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.97036\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.5305 - categorical_accuracy: 0.9045 - val_loss: 0.7807 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.97036 to 0.78074, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.4354 - categorical_accuracy: 0.9283 - val_loss: 0.7786 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.78074 to 0.77860, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.3318 - categorical_accuracy: 0.9552 - val_loss: 0.6461 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.77860 to 0.64613, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.3050 - categorical_accuracy: 0.9597 - val_loss: 0.9913 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.64613\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.3135 - categorical_accuracy: 0.9552 - val_loss: 1.4646 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.64613\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.3470 - categorical_accuracy: 0.9298 - val_loss: 0.4497 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.64613 to 0.44969, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.2479 - categorical_accuracy: 0.9776 - val_loss: 0.6334 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.44969\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.2270 - categorical_accuracy: 0.9642 - val_loss: 0.6308 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.44969\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.2531 - categorical_accuracy: 0.9597 - val_loss: 0.7877 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.44969\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.2763 - categorical_accuracy: 0.9597 - val_loss: 0.6155 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.44969\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.2615 - categorical_accuracy: 0.9537 - val_loss: 0.7735 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.44969\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.2028 - categorical_accuracy: 0.9776 - val_loss: 0.8700 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.44969\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.1643 - categorical_accuracy: 0.9806 - val_loss: 0.5556 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.44969\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.1341 - categorical_accuracy: 0.9940 - val_loss: 0.5542 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.44969\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.1112 - categorical_accuracy: 0.9985 - val_loss: 0.3578 - val_categorical_accuracy: 0.8900\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.44969 to 0.35780, saving model to model_init_2020-11-0718_54_55.249466/model-conv_l2_b10_e30_i96.h5\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.1044 - categorical_accuracy: 0.9970 - val_loss: 0.7014 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.35780\n"
     ]
    }
   ],
   "source": [
    "modell = Models()\n",
    "input_shape = (30,96,96, 3)\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b10_e30_f30_i96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_41 (Conv3D)           (None, 30, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling (None, 30, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_42 (Conv3D)           (None, 30, 60, 60, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 30, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_42 (MaxPooling (None, 15, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_43 (Conv3D)           (None, 15, 30, 30, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 15, 30, 30, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_43 (MaxPooling (None, 7, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_44 (Conv3D)           (None, 7, 15, 15, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 7, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_44 (MaxPooling (None, 3, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_45 (Conv3D)           (None, 3, 7, 7, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 3, 7, 7, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_45 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 119s 2s/step - loss: 5.0533 - categorical_accuracy: 0.3786 - val_loss: 3.8158 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.81575, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 113s 2s/step - loss: 3.4819 - categorical_accuracy: 0.5189 - val_loss: 3.4642 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.81575 to 3.46420, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 125s 2s/step - loss: 2.7890 - categorical_accuracy: 0.5652 - val_loss: 2.9497 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.46420 to 2.94972, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 114s 2s/step - loss: 2.2066 - categorical_accuracy: 0.6253 - val_loss: 2.0904 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.94972 to 2.09038, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 121s 2s/step - loss: 1.8182 - categorical_accuracy: 0.6797 - val_loss: 1.5923 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.09038 to 1.59232, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.5331 - categorical_accuracy: 0.7473 - val_loss: 2.6628 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.59232\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.3346 - categorical_accuracy: 0.7328 - val_loss: 1.1638 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.59232 to 1.16380, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 126s 2s/step - loss: 1.1027 - categorical_accuracy: 0.8010 - val_loss: 1.0681 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.16380 to 1.06810, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 125s 2s/step - loss: 1.0366 - categorical_accuracy: 0.7741 - val_loss: 2.4744 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.06810\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.8752 - categorical_accuracy: 0.8234 - val_loss: 1.3127 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.06810\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.7515 - categorical_accuracy: 0.8537 - val_loss: 1.1899 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.06810\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6021 - categorical_accuracy: 0.8995 - val_loss: 0.8798 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.06810 to 0.87980, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.5612 - categorical_accuracy: 0.8951 - val_loss: 2.2602 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.87980\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.5093 - categorical_accuracy: 0.9104 - val_loss: 1.3262 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.87980\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.3741 - categorical_accuracy: 0.9537 - val_loss: 1.0736 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.3544 - categorical_accuracy: 0.9612 - val_loss: 0.6906 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.87980 to 0.69058, saving model to model_init_2020-11-0719_47_31.771017/model-conv_l2_b10_e30_i120.h5\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.2871 - categorical_accuracy: 0.9716 - val_loss: 1.1710 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.69058\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.3052 - categorical_accuracy: 0.9567 - val_loss: 1.0277 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.69058\n",
      "Epoch 19/30\n"
     ]
    }
   ],
   "source": [
    "modell = Models()\n",
    "input_shape = (30,120,120, 3)\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b10_e30f_30_i120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_14 (Conv3D)           (None, 27, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 27, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 27, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 27, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 27, 60, 60, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 27, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 27, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 13, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 13, 30, 30, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 13, 30, 30, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 13, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 6, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 6, 15, 15, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 6, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 6, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 3, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 3, 7, 7, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 3, 7, 7, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Epoch 1/7\n",
      "Project_data/train ; batch size = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 108s 2s/step - loss: 5.2659 - categorical_accuracy: 0.3611 - val_loss: 3.9149 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.91493, saving model to model_init_2020-11-0911_06_23.069755/model-conv_l2_b10_e7_i120.h5\n",
      "Epoch 2/7\n",
      "67/67 [==============================] - 106s 2s/step - loss: 3.6355 - categorical_accuracy: 0.4681 - val_loss: 3.0433 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.91493 to 3.04329, saving model to model_init_2020-11-0911_06_23.069755/model-conv_l2_b10_e7_i120.h5\n",
      "Epoch 3/7\n",
      "67/67 [==============================] - 116s 2s/step - loss: 2.8788 - categorical_accuracy: 0.5528 - val_loss: 3.7301 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.04329\n",
      "Epoch 4/7\n",
      "67/67 [==============================] - 106s 2s/step - loss: 2.3966 - categorical_accuracy: 0.5875 - val_loss: 5.0014 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.04329\n",
      "Epoch 5/7\n",
      "67/67 [==============================] - 112s 2s/step - loss: 1.9824 - categorical_accuracy: 0.6756 - val_loss: 3.4558 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.04329\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 6/7\n",
      "67/67 [==============================] - 109s 2s/step - loss: 1.6728 - categorical_accuracy: 0.7259 - val_loss: 1.5390 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.04329 to 1.53899, saving model to model_init_2020-11-0911_06_23.069755/model-conv_l2_b10_e7_i120.h5\n",
      "Epoch 7/7\n",
      "67/67 [==============================] - 112s 2s/step - loss: 1.3462 - categorical_accuracy: 0.7940 - val_loss: 1.5233 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.53899 to 1.52328, saving model to model_init_2020-11-0911_06_23.069755/model-conv_l2_b10_e7_i120.h5\n"
     ]
    }
   ],
   "source": [
    "modell = Models()\n",
    "input_shape = (27,120,120, 3)\n",
    "batch_size = 10\n",
    "num_epochs = 7\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b10_e7_f27_i120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 20, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 20, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 20, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 10, 24, 24, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 24, 24, 32)    13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 24, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 5, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 5, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 5, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 2, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 168s 3s/step - loss: 5.1032 - categorical_accuracy: 0.3348 - val_loss: 4.1101 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-11-0821_40_51.284117/model-00001-5.11135-0.33484-4.11014-0.30000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 87s 1s/step - loss: 3.5574 - categorical_accuracy: 0.3930 - val_loss: 3.1523 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-11-0821_40_51.284117/model-00002-3.56170-0.39367-3.15235-0.42000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 89s 1s/step - loss: 2.9084 - categorical_accuracy: 0.4542 - val_loss: 2.9858 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-11-0821_40_51.284117/model-00003-2.90839-0.45551-2.98577-0.32000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 87s 1s/step - loss: 2.4727 - categorical_accuracy: 0.4781 - val_loss: 3.3261 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-11-0821_40_51.284117/model-00004-2.47321-0.47964-3.32608-0.32000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 90s 1s/step - loss: 2.0644 - categorical_accuracy: 0.5726 - val_loss: 2.0394 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-11-0821_40_51.284117/model-00005-2.06841-0.57164-2.03941-0.51000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 112s 2s/step - loss: 1.8730 - categorical_accuracy: 0.5681 - val_loss: 1.6299 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-11-0821_40_51.284117/model-00006-1.87689-0.56712-1.62992-0.60000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 67s 1s/step - loss: 1.6154 - categorical_accuracy: 0.6010 - val_loss: 1.7835 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-11-0821_40_51.284117/model-00007-1.61543-0.60030-1.78350-0.47000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 70s 1s/step - loss: 1.3611 - categorical_accuracy: 0.6805 - val_loss: 2.1783 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-11-0821_40_51.284117/model-00008-1.36781-0.67722-2.17830-0.38000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 68s 1s/step - loss: 1.2328 - categorical_accuracy: 0.6965 - val_loss: 1.3202 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-11-0821_40_51.284117/model-00009-1.23570-0.69683-1.32015-0.70000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 67s 999ms/step - loss: 1.0985 - categorical_accuracy: 0.7129 - val_loss: 1.0204 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-11-0821_40_51.284117/model-00010-1.09353-0.71342-1.02043-0.76000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 77s 1s/step - loss: 0.9063 - categorical_accuracy: 0.7801 - val_loss: 1.0925 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-11-0821_40_51.284117/model-00011-0.90151-0.78130-1.09247-0.70000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 67s 1000ms/step - loss: 0.9210 - categorical_accuracy: 0.7950 - val_loss: 1.3883 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-11-0821_40_51.284117/model-00012-0.92182-0.79638-1.38830-0.71000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.7373 - categorical_accuracy: 0.8424 - val_loss: 4.5186 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-11-0821_40_51.284117/model-00013-0.71513-0.84766-4.51856-0.40000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 67s 1s/step - loss: 0.8556 - categorical_accuracy: 0.7741 - val_loss: 2.4309 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-11-0821_40_51.284117/model-00014-0.85471-0.77526-2.43087-0.33000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 67s 1s/step - loss: 0.6988 - categorical_accuracy: 0.8343 - val_loss: 1.0192 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-11-0821_40_51.284117/model-00015-0.70250-0.83258-1.01918-0.67000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.6432 - categorical_accuracy: 0.8428 - val_loss: 0.8732 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-11-0821_40_51.284117/model-00016-0.64362-0.84465-0.87321-0.73000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 78s 1s/step - loss: 0.5395 - categorical_accuracy: 0.8746 - val_loss: 1.8132 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-11-0821_40_51.284117/model-00017-0.53968-0.87330-1.81322-0.61000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 77s 1s/step - loss: 0.4535 - categorical_accuracy: 0.9000 - val_loss: 1.1527 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-11-0821_40_51.284117/model-00018-0.45594-0.89894-1.15273-0.67000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 77s 1s/step - loss: 0.4228 - categorical_accuracy: 0.9119 - val_loss: 2.2527 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-11-0821_40_51.284117/model-00019-0.42516-0.91101-2.25274-0.52000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 68s 1s/step - loss: 0.4043 - categorical_accuracy: 0.9130 - val_loss: 0.5481 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-11-0821_40_51.284117/model-00020-0.39624-0.91554-0.54813-0.86000.h5\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - L2b10 - Best model\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (20,96,96, 3)\n",
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b10_e20_f20_i96')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 18, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 18, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 18, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 18, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 18, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 18, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 18, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 9, 24, 24, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 9, 24, 24, 32)     13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 24, 24, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 24, 24, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 4, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 2, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 2, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 182s 1s/step - loss: 4.9675 - categorical_accuracy: 0.3123 - val_loss: 3.7023 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-11-0821_04_53.497170/model-00001-4.97095-0.31222-3.70225-0.42000.h5\n",
      "Epoch 2/15\n",
      "133/133 [==============================] - 80s 603ms/step - loss: 3.2914 - categorical_accuracy: 0.3694 - val_loss: 2.7529 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-11-0821_04_53.497170/model-00002-3.29328-0.36953-2.75290-0.44000.h5\n",
      "Epoch 3/15\n",
      "133/133 [==============================] - 80s 601ms/step - loss: 2.6103 - categorical_accuracy: 0.3905 - val_loss: 2.8306 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-11-0821_04_53.497170/model-00003-2.61064-0.39065-2.83058-0.23000.h5\n",
      "Epoch 4/15\n",
      "133/133 [==============================] - 80s 600ms/step - loss: 2.2172 - categorical_accuracy: 0.4135 - val_loss: 1.7623 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-11-0821_04_53.497170/model-00004-2.21988-0.41176-1.76227-0.55000.h5\n",
      "Epoch 5/15\n",
      "133/133 [==============================] - 80s 604ms/step - loss: 1.8228 - categorical_accuracy: 0.4757 - val_loss: 1.8994 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-11-0821_04_53.497170/model-00005-1.82399-0.47511-1.89936-0.39000.h5\n",
      "Epoch 6/15\n",
      "133/133 [==============================] - 100s 754ms/step - loss: 1.5931 - categorical_accuracy: 0.5133 - val_loss: 1.5180 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-11-0821_04_53.497170/model-00006-1.59281-0.51282-1.51798-0.52000.h5\n",
      "Epoch 7/15\n",
      "133/133 [==============================] - 66s 498ms/step - loss: 1.3972 - categorical_accuracy: 0.5594 - val_loss: 1.1976 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-11-0821_04_53.497170/model-00007-1.39527-0.56109-1.19757-0.64000.h5\n",
      "Epoch 8/15\n",
      "133/133 [==============================] - 65s 486ms/step - loss: 1.2580 - categorical_accuracy: 0.5734 - val_loss: 1.0606 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-11-0821_04_53.497170/model-00008-1.25657-0.57315-1.06062-0.72000.h5\n",
      "Epoch 9/15\n",
      "133/133 [==============================] - 62s 465ms/step - loss: 1.1033 - categorical_accuracy: 0.6321 - val_loss: 1.9574 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-11-0821_04_53.497170/model-00009-1.10392-0.63198-1.95735-0.48000.h5\n",
      "Epoch 10/15\n",
      "133/133 [==============================] - 63s 474ms/step - loss: 1.0384 - categorical_accuracy: 0.6496 - val_loss: 1.0031 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-11-0821_04_53.497170/model-00010-1.03917-0.64857-1.00312-0.60000.h5\n",
      "Epoch 11/15\n",
      "133/133 [==============================] - 64s 479ms/step - loss: 0.9713 - categorical_accuracy: 0.6566 - val_loss: 1.0417 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-11-0821_04_53.497170/model-00011-0.96760-0.65762-1.04173-0.58000.h5\n",
      "Epoch 12/15\n",
      "133/133 [==============================] - 63s 473ms/step - loss: 0.8958 - categorical_accuracy: 0.6827 - val_loss: 0.7833 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-11-0821_04_53.497170/model-00012-0.89685-0.68175-0.78332-0.71000.h5\n",
      "Epoch 13/15\n",
      "133/133 [==============================] - 60s 454ms/step - loss: 0.8437 - categorical_accuracy: 0.7253 - val_loss: 1.0181 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-11-0821_04_53.497170/model-00013-0.84360-0.72549-1.01808-0.66000.h5\n",
      "Epoch 14/15\n",
      "133/133 [==============================] - 61s 459ms/step - loss: 0.7159 - categorical_accuracy: 0.7669 - val_loss: 1.0131 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-11-0821_04_53.497170/model-00014-0.71676-0.76621-1.01305-0.62000.h5\n",
      "Epoch 15/15\n",
      "133/133 [==============================] - 65s 490ms/step - loss: 0.7519 - categorical_accuracy: 0.7348 - val_loss: 0.7036 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-11-0821_04_53.497170/model-00015-0.74902-0.73605-0.70364-0.77000.h5\n"
     ]
    }
   ],
   "source": [
    "# Model 3 - L2b5f18 - Best model 2\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (18,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 15\n",
    "\n",
    "model = modell.conv_l2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b5_e15_f18_i96')\n",
    "#loss_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 25\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_27 (Conv3D)           (None, 28, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 28, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 28, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 14, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 14, 60, 60, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 14, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 14, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 7, 30, 30, 32)     4096      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 3, 15, 15, 64)     16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_30 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 230,829\n",
      "Trainable params: 230,333\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 20\n",
      "Source path =  Project_data/train ; batch size = 20\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 119s 3s/step - loss: 1.8881 - categorical_accuracy: 0.2884 - val_loss: 1.7766 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.77656, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - 117s 3s/step - loss: 1.3203 - categorical_accuracy: 0.4481 - val_loss: 1.5833 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.77656 to 1.58334, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - 106s 3s/step - loss: 1.1667 - categorical_accuracy: 0.4982 - val_loss: 1.3922 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.58334 to 1.39222, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - 122s 4s/step - loss: 1.0262 - categorical_accuracy: 0.5828 - val_loss: 1.2480 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.39222 to 1.24800, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - 119s 4s/step - loss: 0.9689 - categorical_accuracy: 0.6313 - val_loss: 1.1697 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.24800 to 1.16973, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.8590 - categorical_accuracy: 0.6740 - val_loss: 1.0388 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16973 to 1.03884, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - 110s 3s/step - loss: 0.8581 - categorical_accuracy: 0.6659 - val_loss: 0.9254 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03884 to 0.92545, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - 106s 3s/step - loss: 0.7179 - categorical_accuracy: 0.7086 - val_loss: 0.9137 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.92545 to 0.91365, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - 108s 3s/step - loss: 0.6905 - categorical_accuracy: 0.7226 - val_loss: 0.9499 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.91365\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - 115s 3s/step - loss: 0.6541 - categorical_accuracy: 0.7520 - val_loss: 0.9907 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.91365\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.6490 - categorical_accuracy: 0.7741 - val_loss: 0.8344 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.91365 to 0.83444, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.5802 - categorical_accuracy: 0.7873 - val_loss: 0.8715 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.83444\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.5727 - categorical_accuracy: 0.7991 - val_loss: 0.8751 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.83444\n",
      "Epoch 14/25\n",
      "34/34 [==============================] - 120s 4s/step - loss: 0.5595 - categorical_accuracy: 0.7940 - val_loss: 0.8321 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83444 to 0.83214, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - 106s 3s/step - loss: 0.5314 - categorical_accuracy: 0.8138 - val_loss: 0.9504 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.83214\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.4985 - categorical_accuracy: 0.8278 - val_loss: 0.9038 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.83214\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - 115s 3s/step - loss: 0.5012 - categorical_accuracy: 0.8116 - val_loss: 0.7849 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.83214 to 0.78486, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - 108s 3s/step - loss: 0.4666 - categorical_accuracy: 0.8484 - val_loss: 0.7933 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.78486\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.4339 - categorical_accuracy: 0.8344 - val_loss: 0.8218 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.78486\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.3565 - categorical_accuracy: 0.9058 - val_loss: 0.7779 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.78486 to 0.77788, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - 111s 3s/step - loss: 0.5160 - categorical_accuracy: 0.7969 - val_loss: 0.7928 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.77788\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - 115s 3s/step - loss: 0.4078 - categorical_accuracy: 0.8668 - val_loss: 0.7833 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.77788\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.3853 - categorical_accuracy: 0.8896 - val_loss: 0.7195 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.77788 to 0.71955, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.3229 - categorical_accuracy: 0.8845 - val_loss: 0.6981 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.71955 to 0.69814, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 25/25\n",
      "34/34 [==============================] - 107s 3s/step - loss: 0.2956 - categorical_accuracy: 0.8970 - val_loss: 0.7036 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.69814\n"
     ]
    }
   ],
   "source": [
    "modell = Models()\n",
    "input_shape = (28,120,120, 3)\n",
    "batch_size = 20\n",
    "num_epochs = 25\n",
    "\n",
    "model = modell.cnn_3(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_l2_b20_e25_f28_i120', optimiser = 'Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4VGX2wPHvSe8JkEIgQEBaIPSAKFhQULCBiCioixVd+1p+6u66urqubtG1gGLDLgr2gop0EFADgnRCJwmQECC95/39cQdMMJXMzSQz5/M8eTJz7zv3nuvIPblvFWMMSiml1DFerg5AKaVU86KJQSmlVBWaGJRSSlWhiUEppVQVmhiUUkpVoYlBKaVUFZoYlKonEXlTRP5Rz7K7RWRkY4+jlCtoYlBKKVWFJgallFJVaGJQbsVRhXO/iPwqIvki8rqIxIjINyKSKyLzRaRVpfKXiMhGETkqIotFJKHSvgEissbxuQ+BgBPOdZGIrHV8doWI9D3JmG8Ske0iclhEvhCRdo7tIiL/E5EMEcl2XFOiY98FIrLJEVuaiNx3Uv/BlKqGJgblji4DRgHdgYuBb4A/A5FY/8/fCSAi3YFZwN1AFDAX+FJE/ETED/gMeAdoDcxxHBfHZwcCM4GbgTbAy8AXIuLfkEBF5BzgSWAiEAvsAT5w7D4PONNxHRHAFUCWY9/rwM3GmFAgEVjYkPMqVRtNDModvWCMOWiMSQOWAT8aY34xxhQDnwIDHOWuAL42xnxvjCkF/gsEAqcDQwFf4FljTKkx5iPg50rnuAl42RjzozGm3BjzFlDs+FxDXAXMNMasccT3EHCaiMQDpUAo0BMQY8xmY8x+x+dKgV4iEmaMOWKMWdPA8ypVI00Myh0drPS6sJr3IY7X7bD+QgfAGFMB7APaO/almaqzTO6p9LoTcK+jGumoiBwFOjg+1xAnxpCH9VTQ3hizEJgGTAcOisgrIhLmKHoZcAGwR0SWiMhpDTyvUjXSxKA8WTrWDR6w6vSxbu5pwH6gvWPbMR0rvd4HPGGMiaj0E2SMmdXIGIKxqqbSAIwxzxtjBgG9saqU7nds/9kYMxaIxqrymt3A8ypVI00MypPNBi4UkXNFxBe4F6s6aAWwEigD7hQRHxEZDwyp9NlXgVtE5FRHI3GwiFwoIqENjOF94DoR6e9on/gnVtXXbhEZ7Di+L5APFAHljjaQq0Qk3FEFlgOUN+K/g1JVaGJQHssYsxW4GngBOITVUH2xMabEGFMCjAeuBY5gtUd8UumzyVjtDNMc+7c7yjY0hgXAw8DHWE8ppwBXOnaHYSWgI1jVTVlY7SAA1wC7RSQHuMVxHUo5hehCPUoppSrTJwallFJVaGJQSilVhSYGpZRSVWhiUEopVYWPqwNoqMjISBMfH+/qMJRSqkVZvXr1IWNMVH3KtrjEEB8fT3JysqvDUEqpFkVE9tRdyqJVSUopparQxKCUUqoKTQxKKaWqaHFtDNUpLS0lNTWVoqIiV4diu4CAAOLi4vD19XV1KEopN+UWiSE1NZXQ0FDi4+OpOhmmezHGkJWVRWpqKp07d3Z1OEopN+UWVUlFRUW0adPGrZMCgIjQpk0bj3gyUkq5jlskBsDtk8IxnnKdSinXcZvEUJei0nL2ZxdSXqGzySqlVG08JjGUlFWQmVtMUanz1zM5evQoL774YoM/d8EFF3D06FGnx6OUUo3hMYkhwNcboEkTQ3l57eeaO3cuERERTo9HKaUawy16JdWHr7fg7SUU2pAYHnzwQXbs2EH//v3x9fUlJCSE2NhY1q5dy6ZNmxg3bhz79u2jqKiIu+66i6lTpwK/Te+Rl5fHmDFjGD58OCtWrKB9+/Z8/vnnBAYGOj1WpZSqi9slhr9/uZFN6TnV7isqLccAgY6nh/rq1S6MRy7uXeP+p556ig0bNrB27VoWL17MhRdeyIYNG453KZ05cyatW7emsLCQwYMHc9lll9GmTZsqx0hJSWHWrFm8+uqrTJw4kY8//pirr9bVGpVSTc/tEkNtvEQoraiw/TxDhgypMs7g+eef59NPPwVg3759pKSk/C4xdO7cmf79+wMwaNAgdu/ebXucSilVHbdLDLX9ZX84v4TUIwX0iAnFv4FPDQ0RHBx8/PXixYuZP38+K1euJCgoiLPPPrvacQj+/v7HX3t7e1NYWGhbfEopVRvbGp9FZKaIZIjIhhr2h4vIlyKyTkQ2ish1dsVyTICvdbnOboAODQ0lNze32n3Z2dm0atWKoKAgtmzZwqpVq5x6bqWUcjY7nxjeBKYBb9ew/zZgkzHmYhGJAraKyHvGmBK7Agrw8UYQCksrCHficdu0acOwYcNITEwkMDCQmJiY4/tGjx7NjBkz6Nu3Lz169GDo0KFOPLNSSjmfbYnBGLNUROJrKwKEijWUNwQ4DJTZFQ+Al5fg7+NlS5fV999/v9rt/v7+fPPNN9XuO9aOEBkZyYYNvz1Y3XfffU6PTyml6suV4ximAQlAOrAeuMsYU23LsIhMFZFkEUnOzMxs1EkDfL1tSQxKKeUuXJkYzgfWAu2A/sA0EQmrrqAx5hVjTJIxJikqql5LllavopwAPy9KyisoK7e/d5JSSrVErkwM1wGfGMt2YBfQ07azFR6FgxsJ8rISQlGZJgallKqOKxPDXuBcABGJAXoAO207m28QmAqCiq2qKK1OUkqp6tnW+Cwis4CzgUgRSQUeAXwBjDEzgMeBN0VkPSDAA8aYQ3bFg48fBEci+ZkEeQVTVKKJQSmlqmNnr6RJdexPB86z6/zVColBCrJoyxH2l/rXXV4ppTyQx8yuCoC3LwRHEWLykLJCjHHO2gwnO+02wLPPPktBQYFT4lBKKWfwrMQAEBJNhXgTzRGKndQArYlBKeVO3G6upDp5+VAeFEVY/gFyC3MJ8G38egiVp90eNWoU0dHRzJ49m+LiYi699FL+/ve/k5+fz8SJE0lNTaW8vJyHH36YgwcPkp6ezogRI4iMjGTRokVOuECllGoc90sM3zwIB9bXWsQHQ0VJPsF4gV9Q3cds2wfGPFXj7srTbs+bN4+PPvqIn376CWMMl1xyCUuXLiUzM5N27drx9ddfA9YcSuHh4TzzzDMsWrSIyMjIBl2mUkrZxfOqkgBBKMMHL8rBOHcWjnnz5jFv3jwGDBjAwIED2bJlCykpKfTp04f58+fzwAMPsGzZMsLDnTlbk1JKOY/7PTHU8pd9ZRmH84gp2oWvrx9EdgcRp5zeGMNDDz3EzTff/Lt9q1evZu7cuTz00EOcd955/O1vf3PKOZVSypk88okBwN/Xl4MmAkoLoKj6Fd/qq/K02+effz4zZ84kLy8PgLS0NDIyMkhPTycoKIirr76a++67jzVr1vzus0op1Ry43xNDPQX6enHAhNLOOwev3HQICDvpp4bK026PGTOGyZMnc9pppwEQEhLCu+++y/bt27n//vvx8vLC19eXl156CYCpU6cyZswYYmNjtfFZKdUsiLP68jeVpKQkk5ycXGXb5s2bSUhIaNBxysor2LQ/h/igEsKK0iCiEwS1dmaotjmZ61VKeTYRWW2MSapPWY+tSvLx9sLX24tsgsEnAHIPQAtLkkopZQePTQxgrc1QWFoBoe2gvBgKslwdklJKuZzbJIaTqRIL8PWiuKyCCv8wa/bV3ANQ/VpBzUZLq/pTSrU8bpEYAgICyMrKavBNM9DXG2OMNTVGWDuoKIV8+yZ4bSxjDFlZWQQEBLg6FKWUG3OLXklxcXGkpqbS0GU/S8srOJhTTGmWL0F+PpCXA3uzICwWpHnmzICAAOLi4lwdhlLKjblFYvD19aVz584N/lxZeQWXP/Id1wztxF8vSoB9ufD6JXDu3+CMe22IVCmlmr/m+WdxE/Hx9qJH21A2H3AMcOswBLqPhh+es5YCVUopD2RbYhCRmSKSISIbailztoisFZGNIrLErlhqk9A2jM37c39rnxjxFyjKhhUvuCIcpZRyOTufGN4ERte0U0QigBeBS4wxvYHLbYylRgmxoRzOLyEjt9jaENsXeo+HVS9BXsPaLJRSyh3YlhiMMUuBw7UUmQx8YozZ6yifYVcstUmIDQNg0/5K8yWN+DOUFcLy/7kiJKWUcilXtjF0B1qJyGIRWS0if6ipoIhMFZFkEUluaM+juvR0JIbNlRNDZDfoNxl+fg2y05x6PqWUau5cmRh8gEHAhcD5wMMi0r26gsaYV4wxScaYpKioKKcGER7oS/uIQDbvP2GG07MfsAa7LfmXU8+nlFLNnSsTQyrwrTEm3xhzCFgK9HNFIAmxYVWfGAAiOkLSdfDLu5C1wxVhKaWUS7gyMXwOnCEiPiISBJwKbHZFIL1iQ9mZmUdRaXnVHWfeDz7+sOifrghLKaVcws7uqrOAlUAPEUkVkRtE5BYRuQXAGLMZ+Bb4FfgJeM0YU2PXVjslxIZRYWDbwROqk0KiYegfYcNHda4jrZRS7sK2kc/GmEn1KPMf4D92xVBfCZUaoPvGRVTdefodViP0gsfhqtkuiE4ppZqWR498PqZj6yCC/bx/3wANENgKht0NKd/B3lVNH5xSSjUxTQyAl5fQo21o1bEMlZ16C4TEwPy/62I+Sim3p4nB4VjPpGqn7vYLshqi966A7QuaPjillGpCmhgcEmLDyC0qI+1oYfUFBk6x1oVe8HeoaN6L+SilVGNoYnD4rQG6mnYGAB8/a6qMA7/Cps+aMDKllGpamhgcerYNRYTfD3SrrM/lEJUAi56A8rKmC04ppZqQJgaHYH8fOrUOqj0xeHnDuQ9D1nZY+17TBaeUUk1IE0Ml1U6NcaIeF0DcYGsOpdKipglMKaWakCaGShJiw9hzuID84lqqiUSspT9z0iD59aYLTimlmogmhkoSYsMwBrYcqKEB+pjOZ0KXEbDsaSiuo6xSSrUwmhgqSYgNBepogD7m3IehIAtWTrc5KqWUalqaGCppHxFIWIBP/RJD+0GQcDGsmAb5WfYHp5RSTUQTQyUiQs/6NEAfc87DUJoPy5+xNzCllGpCmhhO0Cs2jC0HcqmoqMecSFE9oN8k+OlVyE61PzillGoCmhhOkBAbSkFJOXsPF9TvA2c/6FgC9N/2BqaUUk1EE8MJKq/NUC8RHSHpemsJ0EPbbYxMKaWahp0ruM0UkQwRqXVVNhEZLCLlIjLBrlgaontMKF51TY1xojPvA58Aa6oMpZRq4ex8YngTGF1bARHxBv4FfGdjHA0S4OtNl6gQNtU0mV51ji0BuvET2L/OvuCUUqoJ2JYYjDFLgcN1FLsD+BjIsCuOk1GvqTFOdPodEBBhLQGqlFItmMvaGESkPXApMKMeZaeKSLKIJGdmZtoeW0JsKGlHC8kuLK3/hwIjYPifYPv3sPsH+4JTSimbubLx+VngAWNMeV0FjTGvGGOSjDFJUVFRtgd2rAF6S0OfGoZMhbD28NXdUFLPXk1KKdXMuDIxJAEfiMhuYALwooiMc2E8x/VqaM+kY/yCYNyLcGgbzH/U+YEppVQTcFliMMZ0NsbEG2PigY+AW40xzWJptOhQf1oH+9W8mlttupwNQ2+Fn17W9aGVUi2Snd1VZwErgR4ikioiN4jILSJyi13ndBYRISE2lM0HGvjEcMy5f4OonvDZrVBQV/u7Uko1Lz52HdgYM6kBZa+1K46TldA2jHdW7aGsvAIf7wbmT99AGP8qvHqO1d5w+VvWOg5KKdUC6MjnGiTEhlFcVsHurPyTO0BsXzjnL7Dpc/j1Q+cGp5RSNtLEUINjPZMaNNDtRKffCR1Ph7n3w9G9TopMKaXspYmhBl2jQ/D1lob3TKrMyxsunQHGwKe3QEWdPXOVUsrlNDHUwM/Hi1OiQhqXGABadYIL/g17foCV05wTnFJK2UgTQy0GdWrFih1ZbM9o5LrO/SZZq70teBwOrHdOcEopZRNNDLW4e2R3gv28uXfOr5SVV5z8gUTgoucgqDV8MhVKi5wXpFJKOZkmhlpEhfrz97GJrNt3lFeX7WrcwYLbwNgXIWMTLNSJ9pRSzZcmhjpc3DeWMYlt+d/329h2sJFVSt1GwuAbrbaGnUucE6BSSjmZJoY6iAiPj0skJMCH++asa1yVEsCox6FNN/jsj1B41DlBKqWUE2liqIfIEH8eH5vIr6nZvLx0Z+MO5hcE41+BvIMw9z7nBKiUUk6kiaGeLuwby4V9Y3l2/ja2nOwcSse0HwhnPQDr58D6j5wToFJKOYkmhgZ47JLehAX4ct+cdZQ2tkpp+D0QNxi+vgey05wToFJKOYEmhgZoE+LPP8YlsiEth5cW72jcwbx94NKXobzMam/QUdFKqWZCE0MDjekTy8X92vHCwhQ2pTeySqnNKTD6Sdi1BN6bAPlZzglSKaUaQRPDSXjskt6EB/o5p0pp0BS4+HlrnehXzoK01c4JUimlTpImhpPQKtiPJy5NZNP+HKYv2t74Aw6aAtd/CwjMHA3Jb1gT7ymllAvYuYLbTBHJEJENNey/SkR+dfysEJF+dsVih/N7t2Vc/3ZMW7idjenZjT9g+4Fw8xLofKa1uM9nt0JpYeOPq5RSDWTnE8ObwOha9u8CzjLG9AUeB16xMRZbPHpJb1oF+3Hv7HWUlDWySgmsuZQmz4azHoR1s+D1UXC4kVNxKKVUA9mWGIwxS4EaFzw2xqwwxhxxvF0FxNkVi10igvx48tI+bDmQy7SFKc45qJc3jHjIShBH91ntDlu/dc6xlVKqHppLG8MNwDc17RSRqSKSLCLJmZmZTRhW3Ub2imH8wPZMX7yD9alOqFI6pvt5VtVSq3iYdYU1Zbd2aVVKNQGXJwYRGYGVGB6oqYwx5hVjTJIxJikqKqrpgqunRy7qTWSI1UupuMyJN+9W8XD9PBhwDSz7L7x7mXZpVUrZzqWJQUT6Aq8BY40xLfaOFx7ky5Pj+7D1YC7PL3BSldIxvgEwdprVpXXPCnj5TEjVLq1KKfu4LDGISEfgE+AaY8w2V8XhLOf0jOHyQXHMWLKTdftsmDV10BS44Tvw8oI3RsOat51/DqWUwt7uqrOAlUAPEUkVkRtE5BYRucVR5G9AG+BFEVkrIsl2xdJU/npRL6JD/blj1i/kFJU6/wTtBsDUJRA/HL64E7bPd/45lFIeT0wLG0iVlJRkkpObbw5ZvecwV7y8ipEJMbx09UBExPknKSmA10ZC7n64eSlEdHD+OZRSbkVEVhtjkupT1uWNz+5mUKfW/N/oHny78QBvrthtz0n8gmDi21BeCnOuhbISe86jlPJImhhscNMZXRiZEM0/525mrR3tDQCRXWHci5CWDPP+Ys85lFIeSRODDUSEpy/vT3RoALe9t4ajBTb9Rd/rEjjtdvjpFV3wRynlNPVKDCJyl4iEieV1EVkjIufZHVxLFh7ky/SrBpKRW8R9c9ZhW1vOyEeh42lWY3TGFnvOoZTyKPV9YrjeGJMDnAdEAdcBT9kWlZvo3yGCP1+QwPzNGby6rJFrRdfE2xcmvGG1O8z+AxTn2XMepZTHqG9iONa15gLgDWPMukrbVC2uPT2eMYlt+de3W0neXePUUY0TFguXvQ5ZKfDlnTplt1KqUeqbGFaLyDysxPCdiIQCTphO1P2JCP+a0Je4VoHc/v4vZOUV23OiLmfBiL/Aho/hp1ftOYdSyiPUNzHcADwIDDbGFAC+WNVJqh7CAnyZPnkghwtK+NPsdVRU2PQX/fB7oPto+O7PsO9ne86hlHJ79U0MpwFbjTFHReRq4K+AE6cSdX+J7cN55OJeLN2WyUtLdthzEi8vuHSGVbU051qdcE8pdVLqmxheAgocq6z9H7AH0Ml6GmjykI5c0q8dT8/bysodNt20A1tZg9/yM+CTG3WqbqVUg9U3MZQZq7/lWOA5Y8xzQKh9YbknEeGf4/sQHxnMnR/8QmauTe0N7QbAmH/DjoWw9D/2nEMp5bbqmxhyReQh4BrgaxHxxmpnUA0U4u/Di1cNJLeolLs++IVyu9obBl0L/SbB4qd0sj2lVIPUNzFcARRjjWc4ALQH9E/Rk9SzbRiPjU1kxY4s56/fcIwIXPgMRPeCj2+ylglVSql6qFdicCSD94BwEbkIKDLGaBtDI0xM6sBlA+N4fmEKy1JsWq5UJ9tTSp2E+k6JMRH4CbgcmAj8KCIT7AzMEzw+rjfdokO4+4O1bDuYa89JKk+2N/deHfymlKpTfauS/oI1hmGKMeYPwBDgYfvC8gxBfj68eNUgvLyES6f/wLcb9ttzol6XwBn3Wau+aWO0UqoO9U0MXsaYjErvs+r6rIjMFJEMEdlQw34RkedFZLuI/CoiA+sZi1vpGh3Cl7cPp1tMKLe8u4b/frfVngbpc/5qNUYvegJ+edf5x1dKuY36JoZvReQ7EblWRK4Fvgbm1vGZN4HRtewfA3Rz/EzFGivhkdqGB/DhzUO5cnAHpi3azo1v/Ux2oZOXBhWBi5+HLiOsmVhTvnfu8ZVSbqO+jc/3A68AfYF+wCvGmAfq+MxSoLZZ48YCbxvLKiBCRGLrF7b78ffx5snxffjHuESWbz/E2GnLnd/u4OMHV7wDMb1h9hRIW+Pc4yul3EK9F+oxxnxsjLnHGPMnY8ynTjh3e6ByH8pUxzaPJSJcPbQTs24aSl5xuT3tDv6hcNUcCGoD70+Ew7uce3ylVItXVztBrojkVPOTKyI5jTx3ddN2V1u5LiJTRSRZRJIzM23q2tmMJMW35qs7bGx3CG0LV38MFWXw7mUtZ06lzK3wzYPw/EDYs9LV0SjltmpNDMaYUGNMWDU/ocaYsEaeOxXoUOl9HJBeQxyvGGOSjDFJUVFRjTxty2B7u0NUd5j0AeSkwawroKTAecd2prJia9nSNy6A6UPg59egIAs+vw1KC10dnVJuyZVrPn8B/MHRO2kokG2Msam/Zstke7tDx6Fw2WuQmgwf3wDlZc47dmNl7YB5D8MzCVZsOWkw8u9wz2aY+BYc3gFL/uXqKJVyS2LXWsQiMgs4G4gEDgKP4JhfyRgzQ0QEmIbVc6kAuM4Yk1zXcZOSkkxycp3F3E7y7sPc8u4aCkvKeHpiP0YnOrGd/qdXYe59kHS9NY2GuGhxvvJS2PoNJM+EnYtAvKHHGCuuLiOsacWP+fw2WDsLpi6C2H6uiVepFkREVhtjkupV1rZF6m3iqYkB4EB2Ebe8u5q1+45y57nd+NPIboizbuLzH4Xl/4NzHoYz73POMevr6D5r8N2atyHvAIS1tyYBHHCNtbZEdQqPwLQh1v4bF4K3T5OGrFRL05DEoP+aWpBj7Q4Pf7aB5xekkF9cxl8vTHBOcjj3EchJh4WPQ1g76D+58cesTUkBbJ0Lv35ozf5qDHQbBUnPQtdRdd/oA1vBBf+BOVNg5TQYfre98TYHFRXWtCYFh+H0OyCuXv/GlWowTQwtjL+PN/+6rC/B/j68vnwX5RWGRy7u1fjkIAKXTIO8g/DFHRASA13PdU7Qx1SUw66l8Ots2PwFlORZTwfD/wQDp0CrTg07Xq+x0PMiWPwkJFwMbU5xbrzNzcLHrGo23yDY9Bl0Gg7D7rISqquq/5Rb0qqkFsoYwxNfb+a15bu4emhHHrskES8vJ9wcinKsHkBHdsG1X0O7/o0NFA5usJ4M1n8EufvBP8yav6nvFdbNzasRfSBy9sP0UyG2L0z50n1vkGvegS9uh6QbYNTfrWq3ldOtRvnoXnD6nZB4mTWIUalqaBuDhzDG8NS3W3h5yU4mDenIE+OclBxy9sPro6CsCHpeCOFxEN7B8TsOQtvVfQPKToX1c6yng4xN4OUD3c6DvhOh+2jwDWx8nMesfhO+vAsufs5qm3A3u5bCO5dC5zNh8pzfqtnKS2HDx/DDc9Z/47D2cNptMPAP1kBGpSrRxOBBjDH8d95Wpi/awcSkOJ4a39c5ySFzq3WzPZQCBYdO2CnWILljieJY4ghrD4WHrWSwezlgIG4I9LsCel0KwW0aH1d1jIG3Lob9v8JtP9bcYN0SHUqB1861kvEN30FA+O/LGGPNffXDc7BnuVVm8I1w6i0QEt30MatmSRODhzHG8L/5KTy/IIXLBsbx7wl98XZGcjimtBCy0yB7n/UkcPyn0vvySutXtz7Fqibqezm07uK8OGqTtQNeOh26joQr3nWPKqX8LCsplOTBjQvq1waTmgw/PAubvwJvP6sTwel3uH/7i6qT9kryMCLCPaO64y3C/+Zvo7yigv9e3g8fbyeNX/QNtBb8iexa/X5jIP8Q5KSCeEHbvk1/Y25zCpz9EMx/BDZ9Dr3HNe35na2sGD68ymqTmfJV/Rvm45KsxHhoO6x8Ada+b1W1Xfyse1azKVu4cuSzcrK7Rnbj/vN78NnadP40ex1l5RVNc2IRCImCdgOswWau+mv9tNut88+93+rS2VIZY/UM27sSxr0EHQY3/BiRXa02l7vXwynnwFf3wI6Fzo9VuSVNDG7mthFdeXBMT75cl85dH6yltKmSQ3Pg7QOXvGDNpTSvBS8wuPQ/Vi+ucx6GxPGNO1ZojDWFSFRPmH2t1XakVB20KskN3XLWKXiL8MTczZRVVPDCpIH4+XjI3wCx/aw69R+ehT4T4JQRjT9mRYXVQ6u0EMoKobQISgt+23Zse0U5dDkbgiNP/lzrP7JW2es3Gc64t/Gxg9VDafIH8Oq51lTrNy60ryOAcgva+OzGZi7fxWNfbWJkQgzTrxqAv4+3q0NqGqWF8NIwa1rxW1eCX3D9P5uXYd2cf/3QGstRWlS1Yb0u3n6QOAFOnWpVrTXE3h+t3lVxg+GaT50/JiE1Gd680IrrD5+Dj79zj6+aNe2VpI57e+Vu/vb5Rs7pGc20yQMI8vOQh8Tdy62b4Gm3w/lP1F62tMianmPdB47pOcqtm2fcEPANsEYa+wRYjfC+geATaG33cbw/9rqsyGrsXfs+lOZbnz/1ZmuEtrdv7TEc3gWvjbS6mt44H4JaO++/RWUbPoGProO+V8KlM9yj95aqF00Mqop3V+3hr59tACAyxI92EYG0Cw+0fkcEOH5bryOD/Z0zDqI5+PIua4TwjfOh/aCq+4yBfT9aN/GNn0FxtjVWoN8V1k0zuufJn7co2zrujy9bTx0hba1wYZKMAAAaOElEQVQZYpOuq35cQeFReP08azqSGxfU3PvLWZb826quOuevcOb99p5LNRuaGNTvrNhxiNW7j5CeXUja0SLSjxaSfrSQgpLyKuX8vL2IjQigXXggnaOCuWdUdyJDWmiVQ1G2NV1GYGuYutiqmjm8y6omWjcLjuy2ngYSLoF+V1oji72cWN1WUWE9gfw4A3YssKqZel8KQ26GOEeiKi+F9ybA7h/gD59B/HDnnb8mxsAnU2H9bLj8TSsm5fY0Mah6McaQU1hGmiNJ7D8hafyalk3PtqF8MHVoy62C2vI1fDAZeo+3xgTsXQmIlQT6TbIm3/MPsT+OQynWuhdr34eSXGifZFUz7V4Oa96CsS/CgKvsj+OY0iJ4+xLYvw6unftbolJuSxODcor5mw4y9Z1kRvSI5uVrBjlvwFxTm3MtbPwUIrtbTwZ9r7Cm8XCFohzraeWnVyBru7XtjHvh3L81fSz5h+DVc6zG+psWQkSHuj+jWixNDMpp3lm1h4c/28BVp3bkH+MSnbcwUFMqLbLq+qN6Np/G1ooKa8DZ4Z3WvEaNmWG2MTK2WBMmRnSE679tmsn3Cg5b1753pfXklDhee0g1gWaTGERkNPAc4A28Zox56oT9HYG3gAhHmQeNMXNrO6Ymhqb31DdbmLFkB/83uge3nm1zw6hqetsXwHuXW/NMTZrl3HYWsMZ3pK+F7d9bbS5pq8FUgLe/1RU4ONpKjknXWyPolS2aRWIQEW9gGzAKSAV+BiYZYzZVKvMK8Isx5iUR6QXMNcbE13ZcTQxNr6LCcPeHa/liXTrPXdmfsf3buzok5Ww/vwZf3wtDb4PR/2z88fIyrKeClO+t34WHAbF6h3UdaS0uFNsfdi+FVS9Byjyrcb7P5dassLF9Gx+DqqK5TKI3BNhujNnpCOoDYCywqVIZA4Q5XocD6TbGo06Sl5fwn8v7kpFbxH1z1hEV6s/ppzRidK9qfgbfaDWQr5pudZdNur5hny8rhvRfrESwfT7sX2ttD46y1uHoNgq6jPj9iOtTzrF+DqVY3XvXvmf9dBoOQ/8IPcY4/wlG1cnOJ4YJwGhjzI2O99cApxpjbq9UJhaYB7QCgoGRxpjV1RxrKjAVoGPHjoP27NljS8yqdtmFpUx4aQUHcor46JbT6dFWF4NxKxXlMOtKq2pp8myI6W2txZGfaU0Bnp9Zw/ssaxwIWLPrxg2BbiOtJ4O2/RrWflJ4xFqt7qdXIXsvRHSyem8NuLr6tSiOKcm3pl7P2l7pt+OnrMgaPxISc8KPY1uo431wtFuvgNdcqpIuB84/ITEMMcbcUanMPY4YnhaR04DXgURjTI0zv2lVkmulHS3k0uk/4OMlfHrbMGLCAlwdknKmohyYeb61Ilx1xNuaCyoo0vodHGk9FQRFWk8aXc6GwFaNj6O8DLZ+bVUz7V0JfiHQ/yprBcCCrN9u+odSrESQe0JlQ1icNRV7m67W6PT8TGsAYe5B63dhDbPvBra2FqHqNwmG3vrbanluoLkkhtOAR40x5zvePwRgjHmyUpmNWE8V+xzvdwJDjTEZNR1XE4PrbUzPZuKMlXRsE8ycW04jxN99/vEoIPeAtQqfX3DVG39wJARENH0PqvRfYNUMaxnTitLftgdEQGQ36+Z/LAm06WYtDuUXVPsxy0ocyeKA1R6Sd9D6nXsAMrfAnh+gbR+4+HloP9De62sizSUx+GA1Pp8LpGE1Pk82xmysVOYb4ENjzJsikgAsANqbWoLSxNA8LNmWyfVv/szpp7Rh5rWD8W2pYxxUy5F7wLphh3ewkoBd80kZA5u/tNb1yM+AU/8II/7cNAMhbdSQxGDbv2ZjTBlwO/AdsBmYbYzZKCKPicgljmL3AjeJyDpgFnBtbUlBNR9ndY/iyfF9WJZyiD9/sh792pTtQttC4mXQYYh9SQGssS69LoHbf4JB11kN8i8OhW3z7DtnM6MD3FSj/O/7bTy3IIW7R3bj7pHdXR2OUs63d5U1IWPmFmtqldFPWQ3WLUyzeGJQnuHukd2YMCiOZ+enMDt5n6vDUcr5Og6Fm5fBiL/Clq9g+mBY/ZY1et1NaWJQjSIiPDm+D2d0i+TPn6xn8dYa+w0o1XL5+MFZ98MfV0BMInx5J7x1EWRuc3VkttDEoBrN19uLF68aSLeYUK5942cue2kFb6/cTVZeA1Y+U6oliOwGU76y1hY/uAFmDIPF/7IG+LkRbWNQTnO0oIT3f9rL57+ks/VgLj5ewhndIhk3oD2jesW03Km7lapO7kH47iGrG23rLtDtfIhLsrq3turcfCZsdGgW3VXtoomhZdhyIIfPfknni7VppGcXEejrzXm9YxjXvz3Du0Vq91blPrbNg+XPWOMtyoqsbYGtrXmh4pKs3+0H2duTqh40Mahmo6LC8PPuw3y+Lp2vf91PdmEprYP9uLBPLOMGtGNgx1YtcypvpU5UXmqNGE9bbf2krrZ6MuG4x7bqXDVZhHeAkjwozoHi3Pr9JI6HwTecVHiaGFSzVFJWwZJtmXy2No35mw5SXFZBXKtAbhjemWuGdmq5CwEpVZPiXOtJonKyOHH6jpp4+UJAmLVGhn8o+IdZU4IMuvakQtHEoJq9vOIyvttwgNnJ+/hx12F6twvjiUv70L9DhKtDU8peOelWksjLsG72x2/8lRKAf4jTFy/SxKBaDGMM32w4wN+/3EhGbjHXDO3Efef3ICzA19WhKeVWdICbajFEhAv6xDL/nrOYclo8767aw7lPL+HLdek6zYZSLqKJQTULoQG+PHpJbz67bRhtwwK4Y9YvTHnjZ/Zk5bs6NKU8jiYG1az0jYvgs9uG8ejFvViz5wjn/W8p0xamUFxW7urQlPIYmhhUs+PtJVw7rDPz7zmLkQkx/HfeNi54bhmrdma5OjSlPIImBtVstQ0PYPpVA3nj2sGUlFdw5SuruHf2Og7nl7g6NKXcmiYG1eyN6BnNvLvP4tazT+HztWmc8/RiZizZQV5xmatDU8otaXdV1aJsO5jL419tYlnKISKCfLlhWGemDIvX7q1K1aHZdFcVkdEislVEtovIgzWUmSgim0Rko4i8b2c8quXrHhPKOzecyqe3ns6gjq14+vttDHtqIc/M28rRAq1iUsoZ7Fzz2RtrzedRQCrWms+TjDGbKpXpBswGzjHGHBGRaGNMrRP66xODqmxDWjbTFm7n240HCPbz5prT4rnxjM5Ehjh31KhSLV1zeWIYAmw3xuw0xpQAHwBjTyhzEzDdGHMEoK6koNSJEtuHM+OaQXx79xmM6BnNy0t3MPxfC3n8q01k5BS5OjylWiQ7E0N7oPJaj6mObZV1B7qLyA8iskpERld3IBGZKiLJIpKcmZlpU7iqJevZNoxpkwcy/56zuKBPLG+u2M3wfy/ib59vIP1ooavDU6pFsbMq6XLgfGPMjY731wBDjDF3VCrzFVAKTATigGVAojHmaE3H1aokVR97svJ5afEOPlqdigiM6hVDu/BAWgX7ERHkS+sgPyKC/GgV/NtrPx/tpKfcV0OqkuxcUisV6FDpfRxw4nyzqcAqY0wpsEtEtgLdsNojlDppndoE89Rlfbnj3G7MWLyDhVsyWLw1k4KSmkdQh/j7EBHkS6sgP1oF+9E2zJ9ObYKJbxNMpzZBdGoTRKj2flIewM4nBh+sxudzgTSsm/1kY8zGSmVGYzVITxGRSOAXoL8xpsYhrvrEoBqjqLScowWlHCko4Uh+CUcKSjlcUMJRx+sjBSXH96VnF5GZW3Ut38gQPzo5EsVvCSOY+DZBRAT5ueiqlKpbs3hiMMaUicjtwHeANzDTGLNRRB4Dko0xXzj2nScim4By4P7akoJSjRXg603bcG/ahgfUq3xecRl7swrYk5XP7uO/81m5I4tP1qRVKRsR5EtSp9ac0S2SYV0jOSUqWFenUy2SDnBT6iQVlZaz93ABuw/ls/dwASkH81ix8xD7DluN3e3CAxjWNZLhjkShXWiVKzWLJwal3F2ArzfdY0LpHhNaZfverAKWbc9kecohvtt4gDmrUwHoFRvG8G6RDO8ayZDOrQnw9XZF2ErVSZ8YlLJReYVhfVo2y1MyWb79EKv3HKG03ODn48Xg+FYM7dyGrtEhdIkKoVObIE0Wyja6tKdSzVRBSRk/7jrM8pRDLE85xNaDucf3iUBcq0C6RIbQJSqYLlEhdIkMpktUMG3DArS9QjWKViUp1UwF+fkwokc0I3pEA1bj9q7MfHYeymNnZj47D+WzMzOPn3cfrtK1NsjPm86RVrIY2qU1lw5oT5Cf/vNV9tAnBqWaIWMMB3KKrGSRmedIGPlsz8gj7Wgh4YG+TBrSkSmndyI2PNDV4aoWQKuSlHJTxhiS9xxh5vJdfLfxACLCBX1iuX5YPAM6tnJ1eKoZ06okpdyUiDA4vjWD41uz73ABb63YzYc/7+PLdekM7BjB9cM7M7p3W3y8dXoPdfL0iUGpFi6vuIyPkvfxxord7MkqoF14AH84PZ5JgzsSHuTZU3g8+c1mDmQX8Z8J/Tx+LiytSlLKA5VXGBZuyWDm8l2s3JlFoK83EwbFMeX0eNoE+3GkoISjhaUcLShxTAtS+XUJ2YXW76MFpfj5ePF/5/dkdGJbV1/WSfv0l1T+9OE6AC7qG8tzVw7A28tze3ZpYlDKw21Mz+aNH3bzxdp0SsoraiwnAuGB1sSB1m9fIoL82Lw/hy0Hchnduy2Pje1NdFj9phBpLnZm5nHRC8tJbBfOiJ7R/OvbLVwztBOPje3tsd1+tY1BKQ/Xu104/728Hw+M7smX66xJjVsF+xIRaE07HhHkR6sgX8ICfPGq5q/o0vIKXl22k2fnp/DDM4f4ywUJXDG4Q4u4qRaVlnP7+7/g7+PFc5P6ExseyNGCEl5eupPWwX78aVR3V4fY7GliUMqNRYX6c/3wzg3+nK+3F7ee3ZUxibE8+PGvPPjJej5bm8aT4/vSOTLYhkid559zN7Npfw4zr0063pX3wTE9OZxfwnMLUmgd7MeU0+NdG2Qz59mtMUqpWnWODGbWTUN5anwfNqbnMPrZpby0eAeltVRPudK3G/bz9so93Di8M+f0jDm+XUR4cnwfRvWK4dEvN/L52rRajqI0MSilauXlJVw5pCML7jmLcxz19WOn/cD61GxXh1bFvsMF3P/Rr/SLC+f/Rvf83X4fby9emDSAwfGtuXf2OpZs02WCa6KJQSlVL9FhAbx09SBmXD2IQ3nFjJ2+nH/O3UxhLavi1cQYQ1Fpwz9Xk9LyCu6Y9QsYeGHSwBq7pgb4evPalCS6x4RyyzurWbP3iNNicCfaK0kp1WDZhaU89c0WZv20l46tg/jnpX0Y3i0SgPziMg7mFHEwp5iM3KLjrw/mFJGRU8xBx7ai0gou6hvLP8f3IayRS6Y+OXczLy/dyfTJA7mwb2yd5TNzi5kwYwXZhaXMufk0up0wdbo7ajbdVR1Ldz6HtYLba8aYp2ooNwGYAww2xtR619fEoFTzsWpnFg99sp5dh/Lp1CaIrLwS8orLflcu0NebmDB/osMCiAkLICbUn7IKwzur9tAuIoDnrxxw0lN6LNqawXVv/MxVp3bkiUv71Ptze7MKuGzGCrxF+OiPpxHXKuikzt9SNIvEICLeWGs+jwJSsdZ8nmSM2XRCuVDga8APuF0Tg1ItS1FpOS8v2cm2g7lEh/lbN/4wf2JCAxyJwJ8Qf59qu7qu3nOEO2f9wsGcIu4/vwc3ndGl2u6zNTmQXcQFzy8jOtSfz24b1uD1LDbvz2HiyyuJCvFnzi2n0caNV9lrLonhNOBRY8z5jvcPARhjnjyh3LPAfOA+4D5NDEp5luzCUh78+Fe+2XCAM7tH8czEfvVaBrW8wnDVa6tYty+bL+8YTtfokJM6/8+7D3P1az/So20o7980lBB/9+zF35DEYGfjc3tgX6X3qY5tx4nIAKCDMear2g4kIlNFJFlEkjMztSeBUu4kPNCXF68ayD/GJbJqZxZjnlvGD9sP1fm5FxamsGrnYR4fl3jSSQFgcHxrXrxqIBvTc5j6djLFZc5rFG+p7EwM1T0PHn88EREv4H/AvXUdyBjzijEmyRiTFBUV5cQQlVLNgYhw9dBOfHH7MMIDfbn69R/5z3dbKKthvMTKHVk8vyCF8QPbM2FQXKPPf25CDP++rC8rdmRx9wdrKa9oWZ1ynM3OxJAKdKj0Pg5Ir/Q+FEgEFovIbmAo8IWI1OtRRynlfnq2DeOL24cxcVAHpi/awRWvrCLtaGGVMll5xdz1wS/ERwbz+NhEp537skFx/PXCBL7ZcICz/rOIf3y1idV7DlPhgUnCzjYGH6zG53OBNKzG58nGmI01lF+MtjEopRw+X5vGXz7dgJfAvyf0Y3RiWyoqDNe9+TMrd2bx2a3D6NUuzOnn/erXdD5encry7YcoLTdEh/pzfu+2jElsy5DOrVvsWhfNYhI9Y0yZiNwOfIfVXXWmMWajiDwGJBtjvrDr3Eqplm9s//b07xDBHbN+4ZZ3V3PN0E5Eh/qzZFsmj49LtCUpAFzUtx0X9W1HTlEpi7Zk8M36A8xZvY93Vu2hVZAvo3rFMCYxltO7tsHfp2G9oFoKHeCmlGrWSsoq+M93W3h12S4ALujTlumTBzbpTK8FJWUs3ZbJNxsOsGBzBnnFZYT6+3BOQjRjEttyVvdoAv2ad5JoFt1V7aKJQSnPtGhLBl/9up+/XdyL8EDXrUxXXFbOiu1ZfLNhP99vOsiRglICfL0Y3jWKUb2iOadnDFGhzW88hCYGpZRqAmXlFfy06zDfbjzA/E0HSc8uQgQGdIhgZK8YRiXE0DU6pFmsY6GJQSmlmpgxhk37c5i/KYP5mw+yPs2afbZTmyBGJsQwMiGGwfGtXNZ4rYlBKaVcbH92IQs2W0lixfYsSsorCA/05Zye0YxMiGF4t8gmrRLTxKCUUs1IXnEZy7Zl8v3mgyzaksGRglIA2kcEkhAbSs+2YfR0/I5vE2TLU0Wz6K6qlFLKEuLvw5g+sYzpE0tZeQVr9h4lec9htuzPZcuBHBZtzTw+2trfx4vuMaH0bBtKz9gwEhy/Wwf7NVm8mhiUUqoJ+Xh7MaRza4Z0bn18W3FZOdsz8o4nii0Hclm0NYM5q1OPl4kO9WfqmV248Ywu9sdo+xmUUkrVyt/Hm97twundLrzK9szcYitR7M9l84GcJusGq4lBKaWaqahQf6JCozijW9NOHtoyJ/1QSillG00MSimlqtDEoJRSqgpNDEopparQxKCUUqoKTQxKKaWq0MSglFKqCk0MSimlqmhxk+iJSCaw5yQ/HgkccmI4LY0nX78nXzt49vXrtVs6GWPqNVKuxSWGxhCR5PrOLuiOPPn6PfnawbOvX6+94deuVUlKKaWq0MSglFKqCk9LDK+4OgAX8+Tr9+RrB8++fr32BvKoNgallFJ187QnBqWUUnXQxKCUUqoKj0kMIjJaRLaKyHYRedDV8TQlEdktIutFZK2IJLs6HruJyEwRyRCRDZW2tRaR70UkxfG7lStjtEsN1/6oiKQ5vv+1InKBK2O0i4h0EJFFIrJZRDaKyF2O7Z7y3dd0/Q3+/j2ijUFEvIFtwCggFfgZmGSM2eTSwJqIiOwGkowxHjHIR0TOBPKAt40xiY5t/wYOG2Oecvxh0MoY84Ar47RDDdf+KJBnjPmvK2Ozm4jEArHGmDUiEgqsBsYB1+IZ331N1z+RBn7/nvLEMATYbozZaYwpAT4Axro4JmUTY8xS4PAJm8cCbzlev4X1D8bt1HDtHsEYs98Ys8bxOhfYDLTHc777mq6/wTwlMbQH9lV6n8pJ/gdroQwwT0RWi8hUVwfjIjHGmP1g/QMCol0cT1O7XUR+dVQ1uWVVSmUiEg8MAH7EA7/7E64fGvj9e0pikGq2uX8d2m+GGWMGAmOA2xzVDcpzvAScAvQH9gNPuzYce4lICPAxcLcxJsfV8TS1aq6/wd+/pySGVKBDpfdxQLqLYmlyxph0x+8M4FOsqjVPc9BRB3usLjbDxfE0GWPMQWNMuTGmAngVN/7+RcQX66b4njHmE8dmj/nuq7v+k/n+PSUx/Ax0E5HOIuIHXAl84eKYmoSIBDsaohCRYOA8YEPtn3JLXwBTHK+nAJ+7MJYmdeym6HApbvr9i4gArwObjTHPVNrlEd99Tdd/Mt+/R/RKAnB00XoW8AZmGmOecHFITUJEumA9JQD4AO+7+7WLyCzgbKwphw8CjwCfAbOBjsBe4HJjjNs10tZw7WdjVSMYYDdw87E6d3ciIsOBZcB6oMKx+c9Y9eye8N3XdP2TaOD37zGJQSmlVP14SlWSUkqpetLEoJRSqgpNDEopparQxKCUUqoKTQxKKaWq0MSgVBMSkbNF5CtXx6FUbTQxKKWUqkITg1LVEJGrReQnx/z1L4uIt4jkicjTIrJGRBaISJSjbH8RWeWYpOzTY5OUiUhXEZkvIuscnznFcfgQEflIRLaIyHuOEatKNRuaGJQ6gYgkAFdgTT7YHygHrgKCgTWOCQmXYI0qBngbeMAY0xdr1Omx7e8B040x/YDTsSYwA2vWy7uBXkAXYJjtF6VUA/i4OgClmqFzgUHAz44/5gOxJl6rAD50lHkX+EREwoEIY8wSx/a3gDmO+anaG2M+BTDGFAE4jveTMSbV8X4tEA8st/+ylKofTQxK/Z4AbxljHqqyUeThE8rVNp9MbdVDxZVel6P/DlUzo1VJSv3eAmCCiETD8TWDO2H9e5ngKDMZWG6MyQaOiMgZju3XAEsc8+Cnisg4xzH8RSSoSa9CqZOkf6kodQJjzCYR+SvWqndeQClwG5AP9BaR1UA2VjsEWFM5z3Dc+HcC1zm2XwO8LCKPOY5xeRNehlInTWdXVaqeRCTPGBPi6jiUsptWJSmllKpCnxiUUkpVoU8MSimlqtDEoJRSqgpNDEopparQxKCUUqoKTQxKKaWq+H/HdegSyEi3swAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 17\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_40 (Conv3D)           (None, 18, 96, 96, 8)     648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 18, 96, 96, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 18, 96, 96, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_40 (MaxPooling (None, 18, 48, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_41 (Conv3D)           (None, 18, 48, 48, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 18, 48, 48, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 18, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling (None, 9, 24, 24, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_42 (Conv3D)           (None, 9, 24, 24, 32)     13824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 9, 24, 24, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 9, 24, 24, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_42 (MaxPooling (None, 4, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_43 (Conv3D)           (None, 4, 12, 12, 64)     55296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 4, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 4, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_43 (MaxPooling (None, 2, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_44 (Conv3D)           (None, 2, 6, 6, 128)      221184    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 2, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 2, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_44 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 591,853\n",
      "Trainable params: 591,357\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 68s 509ms/step - loss: 10.4188 - categorical_accuracy: 0.2732 - val_loss: 5.8348 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-11-0523_18_58.517915/model-00001-10.43102-0.27300-5.83479-0.47000.h5\n",
      "Epoch 2/17\n",
      "133/133 [==============================] - 67s 507ms/step - loss: 4.6911 - categorical_accuracy: 0.3554 - val_loss: 3.4912 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-11-0523_18_58.517915/model-00002-4.69464-0.35445-3.49121-0.40000.h5\n",
      "Epoch 3/17\n",
      "133/133 [==============================] - 64s 479ms/step - loss: 2.8934 - categorical_accuracy: 0.3719 - val_loss: 2.6015 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-11-0523_18_58.517915/model-00003-2.89680-0.37104-2.60149-0.27000.h5\n",
      "Epoch 4/17\n",
      "133/133 [==============================] - 62s 466ms/step - loss: 2.0214 - categorical_accuracy: 0.4296 - val_loss: 2.1758 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-11-0523_18_58.517915/model-00004-2.02163-0.42986-2.17584-0.31000.h5\n",
      "Epoch 5/17\n",
      "133/133 [==============================] - 63s 475ms/step - loss: 1.6413 - categorical_accuracy: 0.4311 - val_loss: 1.7979 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-11-0523_18_58.517915/model-00005-1.64306-0.43137-1.79785-0.31000.h5\n",
      "Epoch 6/17\n",
      "133/133 [==============================] - 62s 467ms/step - loss: 1.3677 - categorical_accuracy: 0.5012 - val_loss: 1.4348 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-11-0523_18_58.517915/model-00006-1.36715-0.50075-1.43480-0.41000.h5\n",
      "Epoch 7/17\n",
      "133/133 [==============================] - 64s 483ms/step - loss: 1.3002 - categorical_accuracy: 0.4627 - val_loss: 1.5941 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-11-0523_18_58.517915/model-00007-1.30031-0.46305-1.59415-0.37000.h5\n",
      "Epoch 8/17\n",
      "133/133 [==============================] - 68s 511ms/step - loss: 1.1677 - categorical_accuracy: 0.5113 - val_loss: 0.9156 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-11-0523_18_58.517915/model-00008-1.16758-0.51282-0.91561-0.60000.h5\n",
      "Epoch 9/17\n",
      "133/133 [==============================] - 67s 502ms/step - loss: 1.1351 - categorical_accuracy: 0.5439 - val_loss: 1.5559 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-11-0523_18_58.517915/model-00009-1.13306-0.54449-1.55590-0.40000.h5\n",
      "Epoch 10/17\n",
      "133/133 [==============================] - 66s 498ms/step - loss: 1.1205 - categorical_accuracy: 0.5709 - val_loss: 4.3889 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-11-0523_18_58.517915/model-00010-1.11841-0.57164-4.38895-0.23000.h5\n",
      "Epoch 11/17\n",
      "133/133 [==============================] - 66s 497ms/step - loss: 1.1717 - categorical_accuracy: 0.5674 - val_loss: 1.9404 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-11-0523_18_58.517915/model-00011-1.17314-0.56712-1.94041-0.30000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 12/17\n",
      "133/133 [==============================] - 64s 480ms/step - loss: 1.0382 - categorical_accuracy: 0.6080 - val_loss: 1.0721 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-11-0523_18_58.517915/model-00012-1.03812-0.60784-1.07212-0.60000.h5\n",
      "Epoch 13/17\n",
      "133/133 [==============================] - 66s 500ms/step - loss: 1.0205 - categorical_accuracy: 0.6246 - val_loss: 1.5715 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-11-0523_18_58.517915/model-00013-1.02151-0.62443-1.57149-0.43000.h5\n",
      "Epoch 14/17\n",
      "133/133 [==============================] - 66s 497ms/step - loss: 0.8719 - categorical_accuracy: 0.7022 - val_loss: 1.5031 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-11-0523_18_58.517915/model-00014-0.87305-0.70136-1.50305-0.54000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 15/17\n",
      "133/133 [==============================] - 65s 486ms/step - loss: 0.8425 - categorical_accuracy: 0.6827 - val_loss: 0.7723 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-11-0523_18_58.517915/model-00015-0.84382-0.68175-0.77229-0.78000.h5\n",
      "Epoch 16/17\n",
      "133/133 [==============================] - 62s 465ms/step - loss: 0.8232 - categorical_accuracy: 0.7213 - val_loss: 1.0161 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-11-0523_18_58.517915/model-00016-0.81839-0.72247-1.01606-0.67000.h5\n",
      "Epoch 17/17\n",
      "133/133 [==============================] - 68s 508ms/step - loss: 0.8255 - categorical_accuracy: 0.7038 - val_loss: 2.0137 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-11-0523_18_58.517915/model-00017-0.82662-0.70287-2.01365-0.36000.h5\n"
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (18,96,96, 3)\n",
    "batch_size = 5\n",
    "num_epochs = 17\n",
    "\n",
    "model = modell.conv_Increasedl2(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_increasedl2_b5_e17_f18_i96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_132 (TimeDi (None, 18, 48, 48, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_133 (TimeDi (None, 18, 48, 48, 8)     32        \n",
      "_________________________________________________________________\n",
      "time_distributed_134 (TimeDi (None, 18, 24, 24, 8)     0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 18, 24, 24, 8)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_135 (TimeDi (None, 18, 22, 22, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_136 (TimeDi (None, 18, 22, 22, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_137 (TimeDi (None, 18, 11, 11, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 18, 11, 11, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_138 (TimeDi (None, 18, 11, 11, 32)    2080      \n",
      "_________________________________________________________________\n",
      "time_distributed_139 (TimeDi (None, 18, 11, 11, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_140 (TimeDi (None, 18, 5, 5, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 18, 5, 5, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_141 (TimeDi (None, 18, 800)           0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 18, 64)            51264     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 18, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 18, 128)           8320      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 162,613\n",
      "Trainable params: 162,501\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 20\n",
      "Source path =  Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 69s 2s/step - loss: 3.7514 - categorical_accuracy: 0.2215 - val_loss: 3.5440 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.54403, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 54s 2s/step - loss: 3.4134 - categorical_accuracy: 0.2848 - val_loss: 3.4221 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.54403 to 3.42205, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 67s 2s/step - loss: 3.0196 - categorical_accuracy: 0.3834 - val_loss: 3.8138 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.42205\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 59s 2s/step - loss: 2.8619 - categorical_accuracy: 0.4128 - val_loss: 2.8714 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.42205 to 2.87138, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 60s 2s/step - loss: 2.5644 - categorical_accuracy: 0.4886 - val_loss: 2.4792 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.87138 to 2.47921, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 69s 2s/step - loss: 2.3658 - categorical_accuracy: 0.4982 - val_loss: 2.2261 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.47921 to 2.22615, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 64s 2s/step - loss: 2.1838 - categorical_accuracy: 0.5600 - val_loss: 2.1320 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.22615 to 2.13203, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 59s 2s/step - loss: 1.9632 - categorical_accuracy: 0.6402 - val_loss: 2.0621 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.13203 to 2.06206, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 61s 2s/step - loss: 1.9100 - categorical_accuracy: 0.6085 - val_loss: 2.2437 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.06206\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 70s 2s/step - loss: 1.7108 - categorical_accuracy: 0.6556 - val_loss: 2.1727 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.06206\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 1.5621 - categorical_accuracy: 0.7116 - val_loss: 1.8346 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.06206 to 1.83463, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 59s 2s/step - loss: 1.4521 - categorical_accuracy: 0.7292 - val_loss: 2.0733 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.83463\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 59s 2s/step - loss: 1.3507 - categorical_accuracy: 0.7469 - val_loss: 1.4916 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.83463 to 1.49163, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 1.1718 - categorical_accuracy: 0.8087 - val_loss: 2.4004 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.49163\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 65s 2s/step - loss: 1.1705 - categorical_accuracy: 0.7785 - val_loss: 1.4508 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.49163 to 1.45076, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 58s 2s/step - loss: 1.0332 - categorical_accuracy: 0.8146 - val_loss: 1.5908 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.45076\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 58s 2s/step - loss: 1.0262 - categorical_accuracy: 0.7932 - val_loss: 1.2201 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.45076 to 1.22011, saving model to model_init_2020-11-0813_52_11.508369/model-conv_lstm.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 63s 2s/step - loss: 0.9571 - categorical_accuracy: 0.8175 - val_loss: 1.3712 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.22011\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.9401 - categorical_accuracy: 0.8182 - val_loss: 1.5333 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.22011\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 65s 2s/step - loss: 0.8639 - categorical_accuracy: 0.8396 - val_loss: 1.2803 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.22011\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n"
     ]
    }
   ],
   "source": [
    "# Model 5 - LSTMGRU - \n",
    " \n",
    "modell = Models()\n",
    "input_shape = (18,96,96, 3)\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "\n",
    "model = modell.conv_rnn(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_lstm_b20_e20_f18_i96')\n",
    "#loss_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 16, 48, 48, 8)     1184      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 16, 46, 46, 8)     584       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 16, 23, 23, 8)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 16, 23, 23, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 16, 23, 23, 16)    2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 16, 11, 11, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 16, 11, 11, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 16, 11, 11, 32)    9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 16, 5, 5, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 16, 5, 5, 64)      18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 16, 5, 5, 64)      36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 16, 2, 2, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 601,165\n",
      "Trainable params: 601,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 20\n",
      "Source path =  Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 89s 3s/step - loss: 1.6106 - categorical_accuracy: 0.1957 - val_loss: 1.5986 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59858, saving model to model_init_2020-11-0817_18_38.904592/model-conv_lstm.h5\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - 52s 2s/step - loss: 1.4836 - categorical_accuracy: 0.3488 - val_loss: 1.3522 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59858 to 1.35225, saving model to model_init_2020-11-0817_18_38.904592/model-conv_lstm.h5\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - 55s 2s/step - loss: 1.4319 - categorical_accuracy: 0.3407 - val_loss: 1.5051 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.35225\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - 61s 2s/step - loss: 1.3239 - categorical_accuracy: 0.3760 - val_loss: 1.5352 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.35225\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - 62s 2s/step - loss: 1.3181 - categorical_accuracy: 0.4099 - val_loss: 1.2431 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.35225 to 1.24308, saving model to model_init_2020-11-0817_18_38.904592/model-conv_lstm.h5\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - 52s 2s/step - loss: 1.1739 - categorical_accuracy: 0.4731 - val_loss: 1.1255 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.24308 to 1.12549, saving model to model_init_2020-11-0817_18_38.904592/model-conv_lstm.h5\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - 60s 2s/step - loss: 1.2030 - categorical_accuracy: 0.4430 - val_loss: 1.1423 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.12549\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - 58s 2s/step - loss: 1.1244 - categorical_accuracy: 0.4776 - val_loss: 1.0363 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.12549 to 1.03632, saving model to model_init_2020-11-0817_18_38.904592/model-conv_lstm.h5\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - 54s 2s/step - loss: 1.0945 - categorical_accuracy: 0.4768 - val_loss: 1.3797 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.03632\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - 56s 2s/step - loss: 1.2027 - categorical_accuracy: 0.4452 - val_loss: 1.1461 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.03632\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - 62s 2s/step - loss: 1.0771 - categorical_accuracy: 0.5401 - val_loss: 1.3559 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.03632\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.9838 - categorical_accuracy: 0.5644 - val_loss: 0.9529 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.03632 to 0.95294, saving model to model_init_2020-11-0817_18_38.904592/model-conv_lstm.h5\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - 59s 2s/step - loss: 1.0004 - categorical_accuracy: 0.5460 - val_loss: 1.0270 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.95294\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.8952 - categorical_accuracy: 0.6225 - val_loss: 1.0194 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.95294\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.9045 - categorical_accuracy: 0.5982 - val_loss: 0.9950 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.95294\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n"
     ]
    }
   ],
   "source": [
    "# Model 5 - LSTM\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (16,96,96, 3)\n",
    "batch_size = 20\n",
    "num_epochs = 15\n",
    "\n",
    "model = modell.conv_lstm(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_lstm_b20_e15_f16_i96')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_40 (TimeDis (None, 18, 48, 48, 8)     1184      \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 18, 46, 46, 8)     584       \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 18, 23, 23, 8)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 18, 23, 23, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_44 (TimeDis (None, 18, 23, 23, 16)    2320      \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 18, 11, 11, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_46 (TimeDis (None, 18, 11, 11, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_47 (TimeDis (None, 18, 11, 11, 32)    9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_48 (TimeDis (None, 18, 5, 5, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_49 (TimeDis (None, 18, 5, 5, 64)      18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_50 (TimeDis (None, 18, 5, 5, 64)      36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_51 (TimeDis (None, 18, 2, 2, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_52 (TimeDis (None, 18, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 18, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 601,165\n",
      "Trainable params: 601,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 15\n",
      "Source path =  Project_data/train ; batch size = 15\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 63s 1s/step - loss: 1.6303 - categorical_accuracy: 0.2028 - val_loss: 1.6125 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61252, saving model to model_init_2020-11-0817_42_57.344069/model-conv_lstm_b20_e30.h5\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 62s 1s/step - loss: 1.6153 - categorical_accuracy: 0.2014 - val_loss: 1.6046 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61252 to 1.60456, saving model to model_init_2020-11-0817_42_57.344069/model-conv_lstm_b20_e30.h5\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 59s 1s/step - loss: 1.6153 - categorical_accuracy: 0.1823 - val_loss: 1.6066 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.60456\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 61s 1s/step - loss: 1.6121 - categorical_accuracy: 0.1897 - val_loss: 1.6088 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60456\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 60s 1s/step - loss: 1.6123 - categorical_accuracy: 0.2044 - val_loss: 1.6077 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60456\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 67s 1s/step - loss: 1.6118 - categorical_accuracy: 0.1793 - val_loss: 1.6081 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.60456\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 62s 1s/step - loss: 1.6130 - categorical_accuracy: 0.2118 - val_loss: 1.6086 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60456\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 60s 1s/step - loss: 1.6102 - categorical_accuracy: 0.2013 - val_loss: 1.6105 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60456\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 61s 1s/step - loss: 1.6110 - categorical_accuracy: 0.1822 - val_loss: 1.6057 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.60456\n",
      "Epoch 10/30\n",
      "34/45 [=====================>........] - ETA: 15s - loss: 1.6123 - categorical_accuracy: 0.2078"
     ]
    }
   ],
   "source": [
    "# Model 5 - LSTM b20_e30\n",
    "\n",
    "modell = Models()\n",
    "input_shape = (18,96,96, 3)\n",
    "batch_size = 15\n",
    "num_epochs = 30\n",
    "\n",
    "model = modell.conv_lstm(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "training(batch_size, num_epochs, model, train_generator, val_generator, name='conv_lstm_b15_e30_f18_i96')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model CNN_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_26 (Conv3D)           (None, 16, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 16, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 16, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 8, 60, 60, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 8, 60, 60, 16)     3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 8, 60, 60, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8, 60, 60, 16)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 4, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 4, 30, 30, 32)     4096      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 4, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 4, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 2, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 2, 15, 15, 64)     16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 2, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 230,829\n",
      "Trainable params: 230,333\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 20\n",
      "Source path =  Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 77s 2s/step - loss: 1.7865 - categorical_accuracy: 0.3319 - val_loss: 1.6104 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-11-0822_29_05.871424/model-00001-1.78884-0.33183-1.61035-0.43000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 58s 2s/step - loss: 1.4232 - categorical_accuracy: 0.4636 - val_loss: 1.2298 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-11-0822_29_05.871424/model-00002-1.44131-0.45852-1.22982-0.49000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 68s 2s/step - loss: 1.2047 - categorical_accuracy: 0.5129 - val_loss: 1.1814 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-11-0822_29_05.871424/model-00003-1.18338-0.51735-1.18141-0.48000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 71s 2s/step - loss: 0.9624 - categorical_accuracy: 0.6247 - val_loss: 0.9807 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-11-0822_29_05.871424/model-00004-0.96037-0.63198-0.98071-0.66000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 66s 2s/step - loss: 0.9533 - categorical_accuracy: 0.6144 - val_loss: 0.9401 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-11-0822_29_05.871424/model-00005-0.92055-0.62142-0.94015-0.65000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.8412 - categorical_accuracy: 0.6637 - val_loss: 0.9750 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-11-0822_29_05.871424/model-00006-0.82740-0.66365-0.97498-0.64000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 63s 2s/step - loss: 0.7456 - categorical_accuracy: 0.7116 - val_loss: 0.9725 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-11-0822_29_05.871424/model-00007-0.75327-0.70437-0.97247-0.61000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.6812 - categorical_accuracy: 0.7380 - val_loss: 0.8571 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-11-0822_29_05.871424/model-00008-0.66506-0.74811-0.85710-0.64000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 61s 2s/step - loss: 0.6504 - categorical_accuracy: 0.7542 - val_loss: 0.9313 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-11-0822_29_05.871424/model-00009-0.62957-0.76471-0.93126-0.63000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 67s 2s/step - loss: 0.6024 - categorical_accuracy: 0.7859 - val_loss: 0.8193 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-11-0822_29_05.871424/model-00010-0.57897-0.78884-0.81930-0.70000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 63s 2s/step - loss: 0.5644 - categorical_accuracy: 0.7962 - val_loss: 0.9435 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-11-0822_29_05.871424/model-00011-0.56394-0.79940-0.94354-0.62000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 65s 2s/step - loss: 0.5584 - categorical_accuracy: 0.7940 - val_loss: 0.9870 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-11-0822_29_05.871424/model-00012-0.54013-0.80543-0.98697-0.62000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.4947 - categorical_accuracy: 0.8381 - val_loss: 0.9241 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-11-0822_29_05.871424/model-00013-0.50248-0.83409-0.92412-0.63000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00017999999545281753.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 63s 2s/step - loss: 0.4629 - categorical_accuracy: 0.8241 - val_loss: 0.8879 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-11-0822_29_05.871424/model-00014-0.46009-0.82805-0.88794-0.61000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.4071 - categorical_accuracy: 0.8528 - val_loss: 0.9122 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-11-0822_29_05.871424/model-00015-0.39300-0.86576-0.91225-0.64000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.4199 - categorical_accuracy: 0.8374 - val_loss: 0.8235 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-11-0822_29_05.871424/model-00016-0.42292-0.84163-0.82354-0.67000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00016200000245589763.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 66s 2s/step - loss: 0.4443 - categorical_accuracy: 0.8528 - val_loss: 0.8303 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-11-0822_29_05.871424/model-00017-0.40354-0.86576-0.83031-0.67000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.3624 - categorical_accuracy: 0.8742 - val_loss: 0.9978 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-11-0822_29_05.871424/model-00018-0.33265-0.89593-0.99784-0.61000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 62s 2s/step - loss: 0.3959 - categorical_accuracy: 0.8653 - val_loss: 0.9226 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-11-0822_29_05.871424/model-00019-0.38048-0.87029-0.92260-0.66000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00014579999697161838.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 65s 2s/step - loss: 0.3194 - categorical_accuracy: 0.8948 - val_loss: 0.8076 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-11-0822_29_05.871424/model-00020-0.31228-0.90045-0.80759-0.69000.h5\n"
     ]
    }
   ],
   "source": [
    "modell = Models()\n",
    "input_shape = (16,120,120, 3)\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "\n",
    "model = modell.cnn_3(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_3_b20_e20_i120_f16', optimiser = 'Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_19 (Conv3D)           (None, 28, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 28, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 14, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 14, 60, 60, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 14, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 14, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 7, 30, 30, 32)     4096      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 3, 15, 15, 64)     16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 230,829\n",
      "Trainable params: 230,333\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path = Source path =  Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n",
      " Project_data/val ; batch size = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 121s 4s/step - loss: 2.0130 - categorical_accuracy: 0.2855 - val_loss: 1.6080 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60803, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - 120s 4s/step - loss: 1.3890 - categorical_accuracy: 0.4467 - val_loss: 1.4969 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60803 to 1.49693, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - 110s 3s/step - loss: 1.3015 - categorical_accuracy: 0.5033 - val_loss: 1.2114 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.49693 to 1.21141, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - 109s 3s/step - loss: 1.0608 - categorical_accuracy: 0.5879 - val_loss: 0.9630 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.21141 to 0.96305, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - 107s 3s/step - loss: 0.9152 - categorical_accuracy: 0.6453 - val_loss: 0.9362 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.96305 to 0.93618, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - 121s 4s/step - loss: 0.7942 - categorical_accuracy: 0.7270 - val_loss: 1.0765 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.93618\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - 114s 3s/step - loss: 0.7624 - categorical_accuracy: 0.7285 - val_loss: 1.0217 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.93618\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.7473 - categorical_accuracy: 0.7299 - val_loss: 0.9889 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.93618\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00017999999545281753.\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - 121s 4s/step - loss: 0.6742 - categorical_accuracy: 0.7454 - val_loss: 0.9039 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.93618 to 0.90386, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.6183 - categorical_accuracy: 0.7623 - val_loss: 0.8984 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.90386 to 0.89836, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - 107s 3s/step - loss: 0.5400 - categorical_accuracy: 0.7969 - val_loss: 0.8364 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.89836 to 0.83638, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.5711 - categorical_accuracy: 0.7815 - val_loss: 0.9258 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.83638\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.5789 - categorical_accuracy: 0.8057 - val_loss: 0.9200 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.83638\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - 115s 3s/step - loss: 0.4818 - categorical_accuracy: 0.8462 - val_loss: 0.8007 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83638 to 0.80069, saving model to model_init_2020-11-0911_21_06.758129/model-conv_l2_b20_e15_i120_f28.h5\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - 108s 3s/step - loss: 0.4760 - categorical_accuracy: 0.8285 - val_loss: 0.8145 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80069\n"
     ]
    }
   ],
   "source": [
    "modell = Models()\n",
    "input_shape = (28,120,120, 3)\n",
    "batch_size = 20\n",
    "num_epochs = 15\n",
    "\n",
    "model = modell.cnn_3(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_3_b20_e15_i120_f28', optimiser = 'Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 25\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_27 (Conv3D)           (None, 28, 120, 120, 8)   648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 28, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 28, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 14, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 14, 60, 60, 16)    3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 14, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 14, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 7, 30, 30, 32)     4096      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 3, 15, 15, 64)     16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_30 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 230,829\n",
      "Trainable params: 230,333\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "Source path =  Project_data/val ; batch size = 20\n",
      "Source path =  Project_data/train ; batch size = 20\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 119s 3s/step - loss: 1.8881 - categorical_accuracy: 0.2884 - val_loss: 1.7766 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.77656, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - 117s 3s/step - loss: 1.3203 - categorical_accuracy: 0.4481 - val_loss: 1.5833 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.77656 to 1.58334, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - 106s 3s/step - loss: 1.1667 - categorical_accuracy: 0.4982 - val_loss: 1.3922 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.58334 to 1.39222, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - 122s 4s/step - loss: 1.0262 - categorical_accuracy: 0.5828 - val_loss: 1.2480 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.39222 to 1.24800, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - 119s 4s/step - loss: 0.9689 - categorical_accuracy: 0.6313 - val_loss: 1.1697 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.24800 to 1.16973, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.8590 - categorical_accuracy: 0.6740 - val_loss: 1.0388 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16973 to 1.03884, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - 110s 3s/step - loss: 0.8581 - categorical_accuracy: 0.6659 - val_loss: 0.9254 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03884 to 0.92545, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - 106s 3s/step - loss: 0.7179 - categorical_accuracy: 0.7086 - val_loss: 0.9137 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.92545 to 0.91365, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - 108s 3s/step - loss: 0.6905 - categorical_accuracy: 0.7226 - val_loss: 0.9499 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.91365\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - 115s 3s/step - loss: 0.6541 - categorical_accuracy: 0.7520 - val_loss: 0.9907 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.91365\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.6490 - categorical_accuracy: 0.7741 - val_loss: 0.8344 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.91365 to 0.83444, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.5802 - categorical_accuracy: 0.7873 - val_loss: 0.8715 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.83444\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - 122s 4s/step - loss: 0.5727 - categorical_accuracy: 0.7991 - val_loss: 0.8751 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.83444\n",
      "Epoch 14/25\n",
      "34/34 [==============================] - 120s 4s/step - loss: 0.5595 - categorical_accuracy: 0.7940 - val_loss: 0.8321 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83444 to 0.83214, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - 106s 3s/step - loss: 0.5314 - categorical_accuracy: 0.8138 - val_loss: 0.9504 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.83214\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.4985 - categorical_accuracy: 0.8278 - val_loss: 0.9038 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.83214\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - 115s 3s/step - loss: 0.5012 - categorical_accuracy: 0.8116 - val_loss: 0.7849 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.83214 to 0.78486, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - 108s 3s/step - loss: 0.4666 - categorical_accuracy: 0.8484 - val_loss: 0.7933 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.78486\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.4339 - categorical_accuracy: 0.8344 - val_loss: 0.8218 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.78486\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.3565 - categorical_accuracy: 0.9058 - val_loss: 0.7779 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.78486 to 0.77788, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - 111s 3s/step - loss: 0.5160 - categorical_accuracy: 0.7969 - val_loss: 0.7928 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.77788\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - 115s 3s/step - loss: 0.4078 - categorical_accuracy: 0.8668 - val_loss: 0.7833 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.77788\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - 116s 3s/step - loss: 0.3853 - categorical_accuracy: 0.8896 - val_loss: 0.7195 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.77788 to 0.71955, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.3229 - categorical_accuracy: 0.8845 - val_loss: 0.6981 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.71955 to 0.69814, saving model to model_init_2020-11-0911_54_01.189394/model-conv_l2_b20_e25_i120_f28.h5\n",
      "Epoch 25/25\n",
      "34/34 [==============================] - 107s 3s/step - loss: 0.2956 - categorical_accuracy: 0.8970 - val_loss: 0.7036 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.69814\n"
     ]
    }
   ],
   "source": [
    "modell = Models()\n",
    "input_shape = (28,120,120, 3)\n",
    "batch_size = 20\n",
    "num_epochs = 25\n",
    "\n",
    "model = modell.cnn_3(input_shape)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size, input_shape[0],input_shape[1], input_shape[2]) \n",
    "val_generator = generator(val_path, val_doc, batch_size,input_shape[0], input_shape[1], input_shape[2])\n",
    "history = training(batch_size, num_epochs, model, train_generator, val_generator, name='cnn_3_b20_e25_i120_f28', optimiser = 'Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4VGX2wPHvSe8JkEIgQEBaIPSAKFhQULCBiCioixVd+1p+6u66urqubtG1gGLDLgr2gop0EFADgnRCJwmQECC95/39cQdMMJXMzSQz5/M8eTJz7zv3nuvIPblvFWMMSiml1DFerg5AKaVU86KJQSmlVBWaGJRSSlWhiUEppVQVmhiUUkpVoYlBKaVUFZoYlKonEXlTRP5Rz7K7RWRkY4+jlCtoYlBKKVWFJgallFJVaGJQbsVRhXO/iPwqIvki8rqIxIjINyKSKyLzRaRVpfKXiMhGETkqIotFJKHSvgEissbxuQ+BgBPOdZGIrHV8doWI9D3JmG8Ske0iclhEvhCRdo7tIiL/E5EMEcl2XFOiY98FIrLJEVuaiNx3Uv/BlKqGJgblji4DRgHdgYuBb4A/A5FY/8/fCSAi3YFZwN1AFDAX+FJE/ETED/gMeAdoDcxxHBfHZwcCM4GbgTbAy8AXIuLfkEBF5BzgSWAiEAvsAT5w7D4PONNxHRHAFUCWY9/rwM3GmFAgEVjYkPMqVRtNDModvWCMOWiMSQOWAT8aY34xxhQDnwIDHOWuAL42xnxvjCkF/gsEAqcDQwFf4FljTKkx5iPg50rnuAl42RjzozGm3BjzFlDs+FxDXAXMNMasccT3EHCaiMQDpUAo0BMQY8xmY8x+x+dKgV4iEmaMOWKMWdPA8ypVI00Myh0drPS6sJr3IY7X7bD+QgfAGFMB7APaO/almaqzTO6p9LoTcK+jGumoiBwFOjg+1xAnxpCH9VTQ3hizEJgGTAcOisgrIhLmKHoZcAGwR0SWiMhpDTyvUjXSxKA8WTrWDR6w6vSxbu5pwH6gvWPbMR0rvd4HPGGMiaj0E2SMmdXIGIKxqqbSAIwxzxtjBgG9saqU7nds/9kYMxaIxqrymt3A8ypVI00MypPNBi4UkXNFxBe4F6s6aAWwEigD7hQRHxEZDwyp9NlXgVtE5FRHI3GwiFwoIqENjOF94DoR6e9on/gnVtXXbhEZ7Di+L5APFAHljjaQq0Qk3FEFlgOUN+K/g1JVaGJQHssYsxW4GngBOITVUH2xMabEGFMCjAeuBY5gtUd8UumzyVjtDNMc+7c7yjY0hgXAw8DHWE8ppwBXOnaHYSWgI1jVTVlY7SAA1wC7RSQHuMVxHUo5hehCPUoppSrTJwallFJVaGJQSilVhSYGpZRSVWhiUEopVYWPqwNoqMjISBMfH+/qMJRSqkVZvXr1IWNMVH3KtrjEEB8fT3JysqvDUEqpFkVE9tRdyqJVSUopparQxKCUUqoKTQxKKaWqaHFtDNUpLS0lNTWVoqIiV4diu4CAAOLi4vD19XV1KEopN+UWiSE1NZXQ0FDi4+OpOhmmezHGkJWVRWpqKp07d3Z1OEopN+UWVUlFRUW0adPGrZMCgIjQpk0bj3gyUkq5jlskBsDtk8IxnnKdSinXcZvEUJei0nL2ZxdSXqGzySqlVG08JjGUlFWQmVtMUanz1zM5evQoL774YoM/d8EFF3D06FGnx6OUUo3hMYkhwNcboEkTQ3l57eeaO3cuERERTo9HKaUawy16JdWHr7fg7SUU2pAYHnzwQXbs2EH//v3x9fUlJCSE2NhY1q5dy6ZNmxg3bhz79u2jqKiIu+66i6lTpwK/Te+Rl5fHmDFjGD58OCtWrKB9+/Z8/vnnBAYGOj1WpZSqi9slhr9/uZFN6TnV7isqLccAgY6nh/rq1S6MRy7uXeP+p556ig0bNrB27VoWL17MhRdeyIYNG453KZ05cyatW7emsLCQwYMHc9lll9GmTZsqx0hJSWHWrFm8+uqrTJw4kY8//pirr9bVGpVSTc/tEkNtvEQoraiw/TxDhgypMs7g+eef59NPPwVg3759pKSk/C4xdO7cmf79+wMwaNAgdu/ebXucSilVHbdLDLX9ZX84v4TUIwX0iAnFv4FPDQ0RHBx8/PXixYuZP38+K1euJCgoiLPPPrvacQj+/v7HX3t7e1NYWGhbfEopVRvbGp9FZKaIZIjIhhr2h4vIlyKyTkQ2ish1dsVyTICvdbnOboAODQ0lNze32n3Z2dm0atWKoKAgtmzZwqpVq5x6bqWUcjY7nxjeBKYBb9ew/zZgkzHmYhGJAraKyHvGmBK7Agrw8UYQCksrCHficdu0acOwYcNITEwkMDCQmJiY4/tGjx7NjBkz6Nu3Lz169GDo0KFOPLNSSjmfbYnBGLNUROJrKwKEijWUNwQ4DJTZFQ+Al5fg7+NlS5fV999/v9rt/v7+fPPNN9XuO9aOEBkZyYYNvz1Y3XfffU6PTyml6suV4ximAQlAOrAeuMsYU23LsIhMFZFkEUnOzMxs1EkDfL1tSQxKKeUuXJkYzgfWAu2A/sA0EQmrrqAx5hVjTJIxJikqql5LllavopwAPy9KyisoK7e/d5JSSrVErkwM1wGfGMt2YBfQ07azFR6FgxsJ8rISQlGZJgallKqOKxPDXuBcABGJAXoAO207m28QmAqCiq2qKK1OUkqp6tnW+Cwis4CzgUgRSQUeAXwBjDEzgMeBN0VkPSDAA8aYQ3bFg48fBEci+ZkEeQVTVKKJQSmlqmNnr6RJdexPB86z6/zVColBCrJoyxH2l/rXXV4ppTyQx8yuCoC3LwRHEWLykLJCjHHO2gwnO+02wLPPPktBQYFT4lBKKWfwrMQAEBJNhXgTzRGKndQArYlBKeVO3G6upDp5+VAeFEVY/gFyC3MJ8G38egiVp90eNWoU0dHRzJ49m+LiYi699FL+/ve/k5+fz8SJE0lNTaW8vJyHH36YgwcPkp6ezogRI4iMjGTRokVOuECllGoc90sM3zwIB9bXWsQHQ0VJPsF4gV9Q3cds2wfGPFXj7srTbs+bN4+PPvqIn376CWMMl1xyCUuXLiUzM5N27drx9ddfA9YcSuHh4TzzzDMsWrSIyMjIBl2mUkrZxfOqkgBBKMMHL8rBOHcWjnnz5jFv3jwGDBjAwIED2bJlCykpKfTp04f58+fzwAMPsGzZMsLDnTlbk1JKOY/7PTHU8pd9ZRmH84gp2oWvrx9EdgcRp5zeGMNDDz3EzTff/Lt9q1evZu7cuTz00EOcd955/O1vf3PKOZVSypk88okBwN/Xl4MmAkoLoKj6Fd/qq/K02+effz4zZ84kLy8PgLS0NDIyMkhPTycoKIirr76a++67jzVr1vzus0op1Ry43xNDPQX6enHAhNLOOwev3HQICDvpp4bK026PGTOGyZMnc9pppwEQEhLCu+++y/bt27n//vvx8vLC19eXl156CYCpU6cyZswYYmNjtfFZKdUsiLP68jeVpKQkk5ycXGXb5s2bSUhIaNBxysor2LQ/h/igEsKK0iCiEwS1dmaotjmZ61VKeTYRWW2MSapPWY+tSvLx9sLX24tsgsEnAHIPQAtLkkopZQePTQxgrc1QWFoBoe2gvBgKslwdklJKuZzbJIaTqRIL8PWiuKyCCv8wa/bV3ANQ/VpBzUZLq/pTSrU8bpEYAgICyMrKavBNM9DXG2OMNTVGWDuoKIV8+yZ4bSxjDFlZWQQEBLg6FKWUG3OLXklxcXGkpqbS0GU/S8srOJhTTGmWL0F+PpCXA3uzICwWpHnmzICAAOLi4lwdhlLKjblFYvD19aVz584N/lxZeQWXP/Id1wztxF8vSoB9ufD6JXDu3+CMe22IVCmlmr/m+WdxE/Hx9qJH21A2H3AMcOswBLqPhh+es5YCVUopD2RbYhCRmSKSISIbailztoisFZGNIrLErlhqk9A2jM37c39rnxjxFyjKhhUvuCIcpZRyOTufGN4ERte0U0QigBeBS4wxvYHLbYylRgmxoRzOLyEjt9jaENsXeo+HVS9BXsPaLJRSyh3YlhiMMUuBw7UUmQx8YozZ6yifYVcstUmIDQNg0/5K8yWN+DOUFcLy/7kiJKWUcilXtjF0B1qJyGIRWS0if6ipoIhMFZFkEUluaM+juvR0JIbNlRNDZDfoNxl+fg2y05x6PqWUau5cmRh8gEHAhcD5wMMi0r26gsaYV4wxScaYpKioKKcGER7oS/uIQDbvP2GG07MfsAa7LfmXU8+nlFLNnSsTQyrwrTEm3xhzCFgK9HNFIAmxYVWfGAAiOkLSdfDLu5C1wxVhKaWUS7gyMXwOnCEiPiISBJwKbHZFIL1iQ9mZmUdRaXnVHWfeDz7+sOifrghLKaVcws7uqrOAlUAPEUkVkRtE5BYRuQXAGLMZ+Bb4FfgJeM0YU2PXVjslxIZRYWDbwROqk0KiYegfYcNHda4jrZRS7sK2kc/GmEn1KPMf4D92xVBfCZUaoPvGRVTdefodViP0gsfhqtkuiE4ppZqWR498PqZj6yCC/bx/3wANENgKht0NKd/B3lVNH5xSSjUxTQyAl5fQo21o1bEMlZ16C4TEwPy/62I+Sim3p4nB4VjPpGqn7vYLshqi966A7QuaPjillGpCmhgcEmLDyC0qI+1oYfUFBk6x1oVe8HeoaN6L+SilVGNoYnD4rQG6mnYGAB8/a6qMA7/Cps+aMDKllGpamhgcerYNRYTfD3SrrM/lEJUAi56A8rKmC04ppZqQJgaHYH8fOrUOqj0xeHnDuQ9D1nZY+17TBaeUUk1IE0Ml1U6NcaIeF0DcYGsOpdKipglMKaWakCaGShJiw9hzuID84lqqiUSspT9z0iD59aYLTimlmogmhkoSYsMwBrYcqKEB+pjOZ0KXEbDsaSiuo6xSSrUwmhgqSYgNBepogD7m3IehIAtWTrc5KqWUalqaGCppHxFIWIBP/RJD+0GQcDGsmAb5WfYHp5RSTUQTQyUiQs/6NEAfc87DUJoPy5+xNzCllGpCmhhO0Cs2jC0HcqmoqMecSFE9oN8k+OlVyE61PzillGoCmhhOkBAbSkFJOXsPF9TvA2c/6FgC9N/2BqaUUk1EE8MJKq/NUC8RHSHpemsJ0EPbbYxMKaWahp0ruM0UkQwRqXVVNhEZLCLlIjLBrlgaontMKF51TY1xojPvA58Aa6oMpZRq4ex8YngTGF1bARHxBv4FfGdjHA0S4OtNl6gQNtU0mV51ji0BuvET2L/OvuCUUqoJ2JYYjDFLgcN1FLsD+BjIsCuOk1GvqTFOdPodEBBhLQGqlFItmMvaGESkPXApMKMeZaeKSLKIJGdmZtoeW0JsKGlHC8kuLK3/hwIjYPifYPv3sPsH+4JTSimbubLx+VngAWNMeV0FjTGvGGOSjDFJUVFRtgd2rAF6S0OfGoZMhbD28NXdUFLPXk1KKdXMuDIxJAEfiMhuYALwooiMc2E8x/VqaM+kY/yCYNyLcGgbzH/U+YEppVQTcFliMMZ0NsbEG2PigY+AW40xzWJptOhQf1oH+9W8mlttupwNQ2+Fn17W9aGVUi2Snd1VZwErgR4ikioiN4jILSJyi13ndBYRISE2lM0HGvjEcMy5f4OonvDZrVBQV/u7Uko1Lz52HdgYM6kBZa+1K46TldA2jHdW7aGsvAIf7wbmT99AGP8qvHqO1d5w+VvWOg5KKdUC6MjnGiTEhlFcVsHurPyTO0BsXzjnL7Dpc/j1Q+cGp5RSNtLEUINjPZMaNNDtRKffCR1Ph7n3w9G9TopMKaXspYmhBl2jQ/D1lob3TKrMyxsunQHGwKe3QEWdPXOVUsrlNDHUwM/Hi1OiQhqXGABadYIL/g17foCV05wTnFJK2UgTQy0GdWrFih1ZbM9o5LrO/SZZq70teBwOrHdOcEopZRNNDLW4e2R3gv28uXfOr5SVV5z8gUTgoucgqDV8MhVKi5wXpFJKOZkmhlpEhfrz97GJrNt3lFeX7WrcwYLbwNgXIWMTLNSJ9pRSzZcmhjpc3DeWMYlt+d/329h2sJFVSt1GwuAbrbaGnUucE6BSSjmZJoY6iAiPj0skJMCH++asa1yVEsCox6FNN/jsj1B41DlBKqWUE2liqIfIEH8eH5vIr6nZvLx0Z+MO5hcE41+BvIMw9z7nBKiUUk6kiaGeLuwby4V9Y3l2/ja2nOwcSse0HwhnPQDr58D6j5wToFJKOYkmhgZ47JLehAX4ct+cdZQ2tkpp+D0QNxi+vgey05wToFJKOYEmhgZoE+LPP8YlsiEth5cW72jcwbx94NKXobzMam/QUdFKqWZCE0MDjekTy8X92vHCwhQ2pTeySqnNKTD6Sdi1BN6bAPlZzglSKaUaQRPDSXjskt6EB/o5p0pp0BS4+HlrnehXzoK01c4JUimlTpImhpPQKtiPJy5NZNP+HKYv2t74Aw6aAtd/CwjMHA3Jb1gT7ymllAvYuYLbTBHJEJENNey/SkR+dfysEJF+dsVih/N7t2Vc/3ZMW7idjenZjT9g+4Fw8xLofKa1uM9nt0JpYeOPq5RSDWTnE8ObwOha9u8CzjLG9AUeB16xMRZbPHpJb1oF+3Hv7HWUlDWySgmsuZQmz4azHoR1s+D1UXC4kVNxKKVUA9mWGIwxS4EaFzw2xqwwxhxxvF0FxNkVi10igvx48tI+bDmQy7SFKc45qJc3jHjIShBH91ntDlu/dc6xlVKqHppLG8MNwDc17RSRqSKSLCLJmZmZTRhW3Ub2imH8wPZMX7yD9alOqFI6pvt5VtVSq3iYdYU1Zbd2aVVKNQGXJwYRGYGVGB6oqYwx5hVjTJIxJikqKqrpgqunRy7qTWSI1UupuMyJN+9W8XD9PBhwDSz7L7x7mXZpVUrZzqWJQUT6Aq8BY40xLfaOFx7ky5Pj+7D1YC7PL3BSldIxvgEwdprVpXXPCnj5TEjVLq1KKfu4LDGISEfgE+AaY8w2V8XhLOf0jOHyQXHMWLKTdftsmDV10BS44Tvw8oI3RsOat51/DqWUwt7uqrOAlUAPEUkVkRtE5BYRucVR5G9AG+BFEVkrIsl2xdJU/npRL6JD/blj1i/kFJU6/wTtBsDUJRA/HL64E7bPd/45lFIeT0wLG0iVlJRkkpObbw5ZvecwV7y8ipEJMbx09UBExPknKSmA10ZC7n64eSlEdHD+OZRSbkVEVhtjkupT1uWNz+5mUKfW/N/oHny78QBvrthtz0n8gmDi21BeCnOuhbISe86jlPJImhhscNMZXRiZEM0/525mrR3tDQCRXWHci5CWDPP+Ys85lFIeSRODDUSEpy/vT3RoALe9t4ajBTb9Rd/rEjjtdvjpFV3wRynlNPVKDCJyl4iEieV1EVkjIufZHVxLFh7ky/SrBpKRW8R9c9ZhW1vOyEeh42lWY3TGFnvOoZTyKPV9YrjeGJMDnAdEAdcBT9kWlZvo3yGCP1+QwPzNGby6rJFrRdfE2xcmvGG1O8z+AxTn2XMepZTHqG9iONa15gLgDWPMukrbVC2uPT2eMYlt+de3W0neXePUUY0TFguXvQ5ZKfDlnTplt1KqUeqbGFaLyDysxPCdiIQCTphO1P2JCP+a0Je4VoHc/v4vZOUV23OiLmfBiL/Aho/hp1ftOYdSyiPUNzHcADwIDDbGFAC+WNVJqh7CAnyZPnkghwtK+NPsdVRU2PQX/fB7oPto+O7PsO9ne86hlHJ79U0MpwFbjTFHReRq4K+AE6cSdX+J7cN55OJeLN2WyUtLdthzEi8vuHSGVbU051qdcE8pdVLqmxheAgocq6z9H7AH0Ml6GmjykI5c0q8dT8/bysodNt20A1tZg9/yM+CTG3WqbqVUg9U3MZQZq7/lWOA5Y8xzQKh9YbknEeGf4/sQHxnMnR/8QmauTe0N7QbAmH/DjoWw9D/2nEMp5bbqmxhyReQh4BrgaxHxxmpnUA0U4u/Di1cNJLeolLs++IVyu9obBl0L/SbB4qd0sj2lVIPUNzFcARRjjWc4ALQH9E/Rk9SzbRiPjU1kxY4s56/fcIwIXPgMRPeCj2+ylglVSql6qFdicCSD94BwEbkIKDLGaBtDI0xM6sBlA+N4fmEKy1JsWq5UJ9tTSp2E+k6JMRH4CbgcmAj8KCIT7AzMEzw+rjfdokO4+4O1bDuYa89JKk+2N/deHfymlKpTfauS/oI1hmGKMeYPwBDgYfvC8gxBfj68eNUgvLyES6f/wLcb9ttzol6XwBn3Wau+aWO0UqoO9U0MXsaYjErvs+r6rIjMFJEMEdlQw34RkedFZLuI/CoiA+sZi1vpGh3Cl7cPp1tMKLe8u4b/frfVngbpc/5qNUYvegJ+edf5x1dKuY36JoZvReQ7EblWRK4Fvgbm1vGZN4HRtewfA3Rz/EzFGivhkdqGB/DhzUO5cnAHpi3azo1v/Ux2oZOXBhWBi5+HLiOsmVhTvnfu8ZVSbqO+jc/3A68AfYF+wCvGmAfq+MxSoLZZ48YCbxvLKiBCRGLrF7b78ffx5snxffjHuESWbz/E2GnLnd/u4OMHV7wDMb1h9hRIW+Pc4yul3EK9F+oxxnxsjLnHGPMnY8ynTjh3e6ByH8pUxzaPJSJcPbQTs24aSl5xuT3tDv6hcNUcCGoD70+Ew7uce3ylVItXVztBrojkVPOTKyI5jTx3ddN2V1u5LiJTRSRZRJIzM23q2tmMJMW35qs7bGx3CG0LV38MFWXw7mUtZ06lzK3wzYPw/EDYs9LV0SjltmpNDMaYUGNMWDU/ocaYsEaeOxXoUOl9HJBeQxyvGGOSjDFJUVFRjTxty2B7u0NUd5j0AeSkwawroKTAecd2prJia9nSNy6A6UPg59egIAs+vw1KC10dnVJuyZVrPn8B/MHRO2kokG2Msam/Zstke7tDx6Fw2WuQmgwf3wDlZc47dmNl7YB5D8MzCVZsOWkw8u9wz2aY+BYc3gFL/uXqKJVyS2LXWsQiMgs4G4gEDgKP4JhfyRgzQ0QEmIbVc6kAuM4Yk1zXcZOSkkxycp3F3E7y7sPc8u4aCkvKeHpiP0YnOrGd/qdXYe59kHS9NY2GuGhxvvJS2PoNJM+EnYtAvKHHGCuuLiOsacWP+fw2WDsLpi6C2H6uiVepFkREVhtjkupV1rZF6m3iqYkB4EB2Ebe8u5q1+45y57nd+NPIboizbuLzH4Xl/4NzHoYz73POMevr6D5r8N2atyHvAIS1tyYBHHCNtbZEdQqPwLQh1v4bF4K3T5OGrFRL05DEoP+aWpBj7Q4Pf7aB5xekkF9cxl8vTHBOcjj3EchJh4WPQ1g76D+58cesTUkBbJ0Lv35ozf5qDHQbBUnPQtdRdd/oA1vBBf+BOVNg5TQYfre98TYHFRXWtCYFh+H0OyCuXv/GlWowTQwtjL+PN/+6rC/B/j68vnwX5RWGRy7u1fjkIAKXTIO8g/DFHRASA13PdU7Qx1SUw66l8Ots2PwFlORZTwfD/wQDp0CrTg07Xq+x0PMiWPwkJFwMbU5xbrzNzcLHrGo23yDY9Bl0Gg7D7rISqquq/5Rb0qqkFsoYwxNfb+a15bu4emhHHrskES8vJ9wcinKsHkBHdsG1X0O7/o0NFA5usJ4M1n8EufvBP8yav6nvFdbNzasRfSBy9sP0UyG2L0z50n1vkGvegS9uh6QbYNTfrWq3ldOtRvnoXnD6nZB4mTWIUalqaBuDhzDG8NS3W3h5yU4mDenIE+OclBxy9sPro6CsCHpeCOFxEN7B8TsOQtvVfQPKToX1c6yng4xN4OUD3c6DvhOh+2jwDWx8nMesfhO+vAsufs5qm3A3u5bCO5dC5zNh8pzfqtnKS2HDx/DDc9Z/47D2cNptMPAP1kBGpSrRxOBBjDH8d95Wpi/awcSkOJ4a39c5ySFzq3WzPZQCBYdO2CnWILljieJY4ghrD4WHrWSwezlgIG4I9LsCel0KwW0aH1d1jIG3Lob9v8JtP9bcYN0SHUqB1861kvEN30FA+O/LGGPNffXDc7BnuVVm8I1w6i0QEt30MatmSRODhzHG8L/5KTy/IIXLBsbx7wl98XZGcjimtBCy0yB7n/UkcPyn0vvySutXtz7Fqibqezm07uK8OGqTtQNeOh26joQr3nWPKqX8LCsplOTBjQvq1waTmgw/PAubvwJvP6sTwel3uH/7i6qT9kryMCLCPaO64y3C/+Zvo7yigv9e3g8fbyeNX/QNtBb8iexa/X5jIP8Q5KSCeEHbvk1/Y25zCpz9EMx/BDZ9Dr3HNe35na2sGD68ymqTmfJV/Rvm45KsxHhoO6x8Ada+b1W1Xfyse1azKVu4cuSzcrK7Rnbj/vN78NnadP40ex1l5RVNc2IRCImCdgOswWau+mv9tNut88+93+rS2VIZY/UM27sSxr0EHQY3/BiRXa02l7vXwynnwFf3wI6Fzo9VuSVNDG7mthFdeXBMT75cl85dH6yltKmSQ3Pg7QOXvGDNpTSvBS8wuPQ/Vi+ucx6GxPGNO1ZojDWFSFRPmH2t1XakVB20KskN3XLWKXiL8MTczZRVVPDCpIH4+XjI3wCx/aw69R+ehT4T4JQRjT9mRYXVQ6u0EMoKobQISgt+23Zse0U5dDkbgiNP/lzrP7JW2es3Gc64t/Gxg9VDafIH8Oq51lTrNy60ryOAcgva+OzGZi7fxWNfbWJkQgzTrxqAv4+3q0NqGqWF8NIwa1rxW1eCX3D9P5uXYd2cf/3QGstRWlS1Yb0u3n6QOAFOnWpVrTXE3h+t3lVxg+GaT50/JiE1Gd680IrrD5+Dj79zj6+aNe2VpI57e+Vu/vb5Rs7pGc20yQMI8vOQh8Tdy62b4Gm3w/lP1F62tMianmPdB47pOcqtm2fcEPANsEYa+wRYjfC+geATaG33cbw/9rqsyGrsXfs+lOZbnz/1ZmuEtrdv7TEc3gWvjbS6mt44H4JaO++/RWUbPoGProO+V8KlM9yj95aqF00Mqop3V+3hr59tACAyxI92EYG0Cw+0fkcEOH5bryOD/Z0zDqI5+PIua4TwjfOh/aCq+4yBfT9aN/GNn0FxtjVWoN8V1k0zuufJn7co2zrujy9bTx0hba1wYZKMAAAaOElEQVQZYpOuq35cQeFReP08azqSGxfU3PvLWZb826quOuevcOb99p5LNRuaGNTvrNhxiNW7j5CeXUja0SLSjxaSfrSQgpLyKuX8vL2IjQigXXggnaOCuWdUdyJDWmiVQ1G2NV1GYGuYutiqmjm8y6omWjcLjuy2ngYSLoF+V1oji72cWN1WUWE9gfw4A3YssKqZel8KQ26GOEeiKi+F9ybA7h/gD59B/HDnnb8mxsAnU2H9bLj8TSsm5fY0Mah6McaQU1hGmiNJ7D8hafyalk3PtqF8MHVoy62C2vI1fDAZeo+3xgTsXQmIlQT6TbIm3/MPsT+OQynWuhdr34eSXGifZFUz7V4Oa96CsS/CgKvsj+OY0iJ4+xLYvw6unftbolJuSxODcor5mw4y9Z1kRvSI5uVrBjlvwFxTm3MtbPwUIrtbTwZ9r7Cm8XCFohzraeWnVyBru7XtjHvh3L81fSz5h+DVc6zG+psWQkSHuj+jWixNDMpp3lm1h4c/28BVp3bkH+MSnbcwUFMqLbLq+qN6Np/G1ooKa8DZ4Z3WvEaNmWG2MTK2WBMmRnSE679tmsn3Cg5b1753pfXklDhee0g1gWaTGERkNPAc4A28Zox56oT9HYG3gAhHmQeNMXNrO6Ymhqb31DdbmLFkB/83uge3nm1zw6hqetsXwHuXW/NMTZrl3HYWsMZ3pK+F7d9bbS5pq8FUgLe/1RU4ONpKjknXWyPolS2aRWIQEW9gGzAKSAV+BiYZYzZVKvMK8Isx5iUR6QXMNcbE13ZcTQxNr6LCcPeHa/liXTrPXdmfsf3buzok5Ww/vwZf3wtDb4PR/2z88fIyrKeClO+t34WHAbF6h3UdaS0uFNsfdi+FVS9Byjyrcb7P5dassLF9Gx+DqqK5TKI3BNhujNnpCOoDYCywqVIZA4Q5XocD6TbGo06Sl5fwn8v7kpFbxH1z1hEV6s/ppzRidK9qfgbfaDWQr5pudZdNur5hny8rhvRfrESwfT7sX2ttD46y1uHoNgq6jPj9iOtTzrF+DqVY3XvXvmf9dBoOQ/8IPcY4/wlG1cnOJ4YJwGhjzI2O99cApxpjbq9UJhaYB7QCgoGRxpjV1RxrKjAVoGPHjoP27NljS8yqdtmFpUx4aQUHcor46JbT6dFWF4NxKxXlMOtKq2pp8myI6W2txZGfaU0Bnp9Zw/ssaxwIWLPrxg2BbiOtJ4O2/RrWflJ4xFqt7qdXIXsvRHSyem8NuLr6tSiOKcm3pl7P2l7pt+OnrMgaPxISc8KPY1uo431wtFuvgNdcqpIuB84/ITEMMcbcUanMPY4YnhaR04DXgURjTI0zv2lVkmulHS3k0uk/4OMlfHrbMGLCAlwdknKmohyYeb61Ilx1xNuaCyoo0vodHGk9FQRFWk8aXc6GwFaNj6O8DLZ+bVUz7V0JfiHQ/yprBcCCrN9u+odSrESQe0JlQ1icNRV7m67W6PT8TGsAYe5B63dhDbPvBra2FqHqNwmG3vrbanluoLkkhtOAR40x5zvePwRgjHmyUpmNWE8V+xzvdwJDjTEZNR1XE4PrbUzPZuKMlXRsE8ycW04jxN99/vEoIPeAtQqfX3DVG39wJARENH0PqvRfYNUMaxnTitLftgdEQGQ36+Z/LAm06WYtDuUXVPsxy0ocyeKA1R6Sd9D6nXsAMrfAnh+gbR+4+HloP9De62sizSUx+GA1Pp8LpGE1Pk82xmysVOYb4ENjzJsikgAsANqbWoLSxNA8LNmWyfVv/szpp7Rh5rWD8W2pYxxUy5F7wLphh3ewkoBd80kZA5u/tNb1yM+AU/8II/7cNAMhbdSQxGDbv2ZjTBlwO/AdsBmYbYzZKCKPicgljmL3AjeJyDpgFnBtbUlBNR9ndY/iyfF9WJZyiD9/sh792pTtQttC4mXQYYh9SQGssS69LoHbf4JB11kN8i8OhW3z7DtnM6MD3FSj/O/7bTy3IIW7R3bj7pHdXR2OUs63d5U1IWPmFmtqldFPWQ3WLUyzeGJQnuHukd2YMCiOZ+enMDt5n6vDUcr5Og6Fm5fBiL/Clq9g+mBY/ZY1et1NaWJQjSIiPDm+D2d0i+TPn6xn8dYa+w0o1XL5+MFZ98MfV0BMInx5J7x1EWRuc3VkttDEoBrN19uLF68aSLeYUK5942cue2kFb6/cTVZeA1Y+U6oliOwGU76y1hY/uAFmDIPF/7IG+LkRbWNQTnO0oIT3f9rL57+ks/VgLj5ewhndIhk3oD2jesW03Km7lapO7kH47iGrG23rLtDtfIhLsrq3turcfCZsdGgW3VXtoomhZdhyIIfPfknni7VppGcXEejrzXm9YxjXvz3Du0Vq91blPrbNg+XPWOMtyoqsbYGtrXmh4pKs3+0H2duTqh40Mahmo6LC8PPuw3y+Lp2vf91PdmEprYP9uLBPLOMGtGNgx1YtcypvpU5UXmqNGE9bbf2krrZ6MuG4x7bqXDVZhHeAkjwozoHi3Pr9JI6HwTecVHiaGFSzVFJWwZJtmXy2No35mw5SXFZBXKtAbhjemWuGdmq5CwEpVZPiXOtJonKyOHH6jpp4+UJAmLVGhn8o+IdZU4IMuvakQtHEoJq9vOIyvttwgNnJ+/hx12F6twvjiUv70L9DhKtDU8peOelWksjLsG72x2/8lRKAf4jTFy/SxKBaDGMM32w4wN+/3EhGbjHXDO3Efef3ICzA19WhKeVWdICbajFEhAv6xDL/nrOYclo8767aw7lPL+HLdek6zYZSLqKJQTULoQG+PHpJbz67bRhtwwK4Y9YvTHnjZ/Zk5bs6NKU8jiYG1az0jYvgs9uG8ejFvViz5wjn/W8p0xamUFxW7urQlPIYmhhUs+PtJVw7rDPz7zmLkQkx/HfeNi54bhmrdma5OjSlPIImBtVstQ0PYPpVA3nj2sGUlFdw5SuruHf2Og7nl7g6NKXcmiYG1eyN6BnNvLvP4tazT+HztWmc8/RiZizZQV5xmatDU8otaXdV1aJsO5jL419tYlnKISKCfLlhWGemDIvX7q1K1aHZdFcVkdEislVEtovIgzWUmSgim0Rko4i8b2c8quXrHhPKOzecyqe3ns6gjq14+vttDHtqIc/M28rRAq1iUsoZ7Fzz2RtrzedRQCrWms+TjDGbKpXpBswGzjHGHBGRaGNMrRP66xODqmxDWjbTFm7n240HCPbz5prT4rnxjM5Ehjh31KhSLV1zeWIYAmw3xuw0xpQAHwBjTyhzEzDdGHMEoK6koNSJEtuHM+OaQXx79xmM6BnNy0t3MPxfC3n8q01k5BS5OjylWiQ7E0N7oPJaj6mObZV1B7qLyA8iskpERld3IBGZKiLJIpKcmZlpU7iqJevZNoxpkwcy/56zuKBPLG+u2M3wfy/ib59vIP1ooavDU6pFsbMq6XLgfGPMjY731wBDjDF3VCrzFVAKTATigGVAojHmaE3H1aokVR97svJ5afEOPlqdigiM6hVDu/BAWgX7ERHkS+sgPyKC/GgV/NtrPx/tpKfcV0OqkuxcUisV6FDpfRxw4nyzqcAqY0wpsEtEtgLdsNojlDppndoE89Rlfbnj3G7MWLyDhVsyWLw1k4KSmkdQh/j7EBHkS6sgP1oF+9E2zJ9ObYKJbxNMpzZBdGoTRKj2flIewM4nBh+sxudzgTSsm/1kY8zGSmVGYzVITxGRSOAXoL8xpsYhrvrEoBqjqLScowWlHCko4Uh+CUcKSjlcUMJRx+sjBSXH96VnF5GZW3Ut38gQPzo5EsVvCSOY+DZBRAT5ueiqlKpbs3hiMMaUicjtwHeANzDTGLNRRB4Dko0xXzj2nScim4By4P7akoJSjRXg603bcG/ahgfUq3xecRl7swrYk5XP7uO/81m5I4tP1qRVKRsR5EtSp9ac0S2SYV0jOSUqWFenUy2SDnBT6iQVlZaz93ABuw/ls/dwASkH81ix8xD7DluN3e3CAxjWNZLhjkShXWiVKzWLJwal3F2ArzfdY0LpHhNaZfverAKWbc9kecohvtt4gDmrUwHoFRvG8G6RDO8ayZDOrQnw9XZF2ErVSZ8YlLJReYVhfVo2y1MyWb79EKv3HKG03ODn48Xg+FYM7dyGrtEhdIkKoVObIE0Wyja6tKdSzVRBSRk/7jrM8pRDLE85xNaDucf3iUBcq0C6RIbQJSqYLlEhdIkMpktUMG3DArS9QjWKViUp1UwF+fkwokc0I3pEA1bj9q7MfHYeymNnZj47D+WzMzOPn3cfrtK1NsjPm86RVrIY2qU1lw5oT5Cf/vNV9tAnBqWaIWMMB3KKrGSRmedIGPlsz8gj7Wgh4YG+TBrSkSmndyI2PNDV4aoWQKuSlHJTxhiS9xxh5vJdfLfxACLCBX1iuX5YPAM6tnJ1eKoZ06okpdyUiDA4vjWD41uz73ABb63YzYc/7+PLdekM7BjB9cM7M7p3W3y8dXoPdfL0iUGpFi6vuIyPkvfxxord7MkqoF14AH84PZ5JgzsSHuTZU3g8+c1mDmQX8Z8J/Tx+LiytSlLKA5VXGBZuyWDm8l2s3JlFoK83EwbFMeX0eNoE+3GkoISjhaUcLShxTAtS+XUJ2YXW76MFpfj5ePF/5/dkdGJbV1/WSfv0l1T+9OE6AC7qG8tzVw7A28tze3ZpYlDKw21Mz+aNH3bzxdp0SsoraiwnAuGB1sSB1m9fIoL82Lw/hy0Hchnduy2Pje1NdFj9phBpLnZm5nHRC8tJbBfOiJ7R/OvbLVwztBOPje3tsd1+tY1BKQ/Xu104/728Hw+M7smX66xJjVsF+xIRaE07HhHkR6sgX8ICfPGq5q/o0vIKXl22k2fnp/DDM4f4ywUJXDG4Q4u4qRaVlnP7+7/g7+PFc5P6ExseyNGCEl5eupPWwX78aVR3V4fY7GliUMqNRYX6c/3wzg3+nK+3F7ee3ZUxibE8+PGvPPjJej5bm8aT4/vSOTLYhkid559zN7Npfw4zr0063pX3wTE9OZxfwnMLUmgd7MeU0+NdG2Qz59mtMUqpWnWODGbWTUN5anwfNqbnMPrZpby0eAeltVRPudK3G/bz9so93Di8M+f0jDm+XUR4cnwfRvWK4dEvN/L52rRajqI0MSilauXlJVw5pCML7jmLcxz19WOn/cD61GxXh1bFvsMF3P/Rr/SLC+f/Rvf83X4fby9emDSAwfGtuXf2OpZs02WCa6KJQSlVL9FhAbx09SBmXD2IQ3nFjJ2+nH/O3UxhLavi1cQYQ1Fpwz9Xk9LyCu6Y9QsYeGHSwBq7pgb4evPalCS6x4RyyzurWbP3iNNicCfaK0kp1WDZhaU89c0WZv20l46tg/jnpX0Y3i0SgPziMg7mFHEwp5iM3KLjrw/mFJGRU8xBx7ai0gou6hvLP8f3IayRS6Y+OXczLy/dyfTJA7mwb2yd5TNzi5kwYwXZhaXMufk0up0wdbo7ajbdVR1Ldz6HtYLba8aYp2ooNwGYAww2xtR619fEoFTzsWpnFg99sp5dh/Lp1CaIrLwS8orLflcu0NebmDB/osMCiAkLICbUn7IKwzur9tAuIoDnrxxw0lN6LNqawXVv/MxVp3bkiUv71Ptze7MKuGzGCrxF+OiPpxHXKuikzt9SNIvEICLeWGs+jwJSsdZ8nmSM2XRCuVDga8APuF0Tg1ItS1FpOS8v2cm2g7lEh/lbN/4wf2JCAxyJwJ8Qf59qu7qu3nOEO2f9wsGcIu4/vwc3ndGl2u6zNTmQXcQFzy8jOtSfz24b1uD1LDbvz2HiyyuJCvFnzi2n0caNV9lrLonhNOBRY8z5jvcPARhjnjyh3LPAfOA+4D5NDEp5luzCUh78+Fe+2XCAM7tH8czEfvVaBrW8wnDVa6tYty+bL+8YTtfokJM6/8+7D3P1az/So20o7980lBB/9+zF35DEYGfjc3tgX6X3qY5tx4nIAKCDMear2g4kIlNFJFlEkjMztSeBUu4kPNCXF68ayD/GJbJqZxZjnlvGD9sP1fm5FxamsGrnYR4fl3jSSQFgcHxrXrxqIBvTc5j6djLFZc5rFG+p7EwM1T0PHn88EREv4H/AvXUdyBjzijEmyRiTFBUV5cQQlVLNgYhw9dBOfHH7MMIDfbn69R/5z3dbKKthvMTKHVk8vyCF8QPbM2FQXKPPf25CDP++rC8rdmRx9wdrKa9oWZ1ynM3OxJAKdKj0Pg5Ir/Q+FEgEFovIbmAo8IWI1OtRRynlfnq2DeOL24cxcVAHpi/awRWvrCLtaGGVMll5xdz1wS/ERwbz+NhEp537skFx/PXCBL7ZcICz/rOIf3y1idV7DlPhgUnCzjYGH6zG53OBNKzG58nGmI01lF+MtjEopRw+X5vGXz7dgJfAvyf0Y3RiWyoqDNe9+TMrd2bx2a3D6NUuzOnn/erXdD5encry7YcoLTdEh/pzfu+2jElsy5DOrVvsWhfNYhI9Y0yZiNwOfIfVXXWmMWajiDwGJBtjvrDr3Eqplm9s//b07xDBHbN+4ZZ3V3PN0E5Eh/qzZFsmj49LtCUpAFzUtx0X9W1HTlEpi7Zk8M36A8xZvY93Vu2hVZAvo3rFMCYxltO7tsHfp2G9oFoKHeCmlGrWSsoq+M93W3h12S4ALujTlumTBzbpTK8FJWUs3ZbJNxsOsGBzBnnFZYT6+3BOQjRjEttyVvdoAv2ad5JoFt1V7aKJQSnPtGhLBl/9up+/XdyL8EDXrUxXXFbOiu1ZfLNhP99vOsiRglICfL0Y3jWKUb2iOadnDFGhzW88hCYGpZRqAmXlFfy06zDfbjzA/E0HSc8uQgQGdIhgZK8YRiXE0DU6pFmsY6GJQSmlmpgxhk37c5i/KYP5mw+yPs2afbZTmyBGJsQwMiGGwfGtXNZ4rYlBKaVcbH92IQs2W0lixfYsSsorCA/05Zye0YxMiGF4t8gmrRLTxKCUUs1IXnEZy7Zl8v3mgyzaksGRglIA2kcEkhAbSs+2YfR0/I5vE2TLU0Wz6K6qlFLKEuLvw5g+sYzpE0tZeQVr9h4lec9htuzPZcuBHBZtzTw+2trfx4vuMaH0bBtKz9gwEhy/Wwf7NVm8mhiUUqoJ+Xh7MaRza4Z0bn18W3FZOdsz8o4nii0Hclm0NYM5q1OPl4kO9WfqmV248Ywu9sdo+xmUUkrVyt/Hm97twundLrzK9szcYitR7M9l84GcJusGq4lBKaWaqahQf6JCozijW9NOHtoyJ/1QSillG00MSimlqtDEoJRSqgpNDEopparQxKCUUqoKTQxKKaWq0MSglFKqCk0MSimlqmhxk+iJSCaw5yQ/HgkccmI4LY0nX78nXzt49vXrtVs6GWPqNVKuxSWGxhCR5PrOLuiOPPn6PfnawbOvX6+94deuVUlKKaWq0MSglFKqCk9LDK+4OgAX8+Tr9+RrB8++fr32BvKoNgallFJ187QnBqWUUnXQxKCUUqoKj0kMIjJaRLaKyHYRedDV8TQlEdktIutFZK2IJLs6HruJyEwRyRCRDZW2tRaR70UkxfG7lStjtEsN1/6oiKQ5vv+1InKBK2O0i4h0EJFFIrJZRDaKyF2O7Z7y3dd0/Q3+/j2ijUFEvIFtwCggFfgZmGSM2eTSwJqIiOwGkowxHjHIR0TOBPKAt40xiY5t/wYOG2Oecvxh0MoY84Ar47RDDdf+KJBnjPmvK2Ozm4jEArHGmDUiEgqsBsYB1+IZ331N1z+RBn7/nvLEMATYbozZaYwpAT4Axro4JmUTY8xS4PAJm8cCbzlev4X1D8bt1HDtHsEYs98Ys8bxOhfYDLTHc777mq6/wTwlMbQH9lV6n8pJ/gdroQwwT0RWi8hUVwfjIjHGmP1g/QMCol0cT1O7XUR+dVQ1uWVVSmUiEg8MAH7EA7/7E64fGvj9e0pikGq2uX8d2m+GGWMGAmOA2xzVDcpzvAScAvQH9gNPuzYce4lICPAxcLcxJsfV8TS1aq6/wd+/pySGVKBDpfdxQLqLYmlyxph0x+8M4FOsqjVPc9BRB3usLjbDxfE0GWPMQWNMuTGmAngVN/7+RcQX66b4njHmE8dmj/nuq7v+k/n+PSUx/Ax0E5HOIuIHXAl84eKYmoSIBDsaohCRYOA8YEPtn3JLXwBTHK+nAJ+7MJYmdeym6HApbvr9i4gArwObjTHPVNrlEd99Tdd/Mt+/R/RKAnB00XoW8AZmGmOecHFITUJEumA9JQD4AO+7+7WLyCzgbKwphw8CjwCfAbOBjsBe4HJjjNs10tZw7WdjVSMYYDdw87E6d3ciIsOBZcB6oMKx+c9Y9eye8N3XdP2TaOD37zGJQSmlVP14SlWSUkqpetLEoJRSqgpNDEopparQxKCUUqoKTQxKKaWq0MSgVBMSkbNF5CtXx6FUbTQxKKWUqkITg1LVEJGrReQnx/z1L4uIt4jkicjTIrJGRBaISJSjbH8RWeWYpOzTY5OUiUhXEZkvIuscnznFcfgQEflIRLaIyHuOEatKNRuaGJQ6gYgkAFdgTT7YHygHrgKCgTWOCQmXYI0qBngbeMAY0xdr1Omx7e8B040x/YDTsSYwA2vWy7uBXkAXYJjtF6VUA/i4OgClmqFzgUHAz44/5gOxJl6rAD50lHkX+EREwoEIY8wSx/a3gDmO+anaG2M+BTDGFAE4jveTMSbV8X4tEA8st/+ylKofTQxK/Z4AbxljHqqyUeThE8rVNp9MbdVDxZVel6P/DlUzo1VJSv3eAmCCiETD8TWDO2H9e5ngKDMZWG6MyQaOiMgZju3XAEsc8+Cnisg4xzH8RSSoSa9CqZOkf6kodQJjzCYR+SvWqndeQClwG5AP9BaR1UA2VjsEWFM5z3Dc+HcC1zm2XwO8LCKPOY5xeRNehlInTWdXVaqeRCTPGBPi6jiUsptWJSmllKpCnxiUUkpVoU8MSimlqtDEoJRSqgpNDEopparQxKCUUqoKTQxKKaWq+H/HdegSyEi3swAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
